I"ñ	<ul class="toc__menu">
  <li><a href="#computational-graph">Computational Graph</a>
    <ul>
      <li><a href="#work-out-a-computation-graph">Work Out a Computation Graph</a></li>
      <li><a href="#local-computation">Local Computation</a></li>
      <li><a href="#advantages-of-computation-graphs">Advantages of Computation Graphs</a></li>
    </ul>
  </li>
  <li><a href="#chain-rule">Chain Rule</a>
    <ul>
      <li><a href="#backward-propagation-of-computation-graph">Backward Propagation of Computation Graph</a></li>
      <li><a href="#what-is-a-chain-rule-">What is a Chain Rule ?</a></li>
      <li><a href="#chain-rule-and-computation-graphs">Chain Rule and Computation Graphs</a></li>
    </ul>
  </li>
  <li><a href="#backward-propagation">Backward Propagation</a>
    <ul>
      <li><a href="#backward-propagation-of-addition-node">Backward Propagation of Addition Node</a></li>
      <li><a href="#backward-propagation-of-multiple-node">Backward Propagation of Multiple Node</a></li>
    </ul>
  </li>
  <li><a href="#implementing-a-simple-layer">Implementing a Simple Layer</a>
    <ul>
      <li><a href="#multiplication-layer">Multiplication Layer</a></li>
      <li><a href="#addition-layer">Addition Layer</a></li>
    </ul>
  </li>
  <li><a href="#implement-activation-function-layer">Implement Activation Function Layer</a>
    <ul>
      <li><a href="#relu-layer">ReLU Layer</a></li>
      <li><a href="#sigmoid-layer">Sigmoid Layer</a>
        <ul>
          <li><a href="#1-step">1 Step</a></li>
          <li><a href="#2-step">2 Step</a></li>
          <li><a href="#3-step">3 Step</a></li>
          <li><a href="#4-step">4 Step</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#implementing-the-affine--softmax-layer">Implementing the Affine / Softmax Layer</a>
    <ul>
      <li><a href="#affine-layer">Affine Layer</a></li>
      <li><a href="#affine-layer-for-batch">Affine Layer for Batch</a></li>
      <li><a href="#softmax-with-loss-layer">Softmax-with-Loss Layer</a></li>
    </ul>
  </li>
  <li><a href="#implementation-of-backpropagation">Implementation of Backpropagation</a>
    <ul>
      <li><a href="#implementing-a-neural-network-using-backpropagation">Implementing a Neural Network Using Backpropagation</a></li>
      <li><a href="#verification-of-gradient-with-backpropagation">Verification of Gradient with Backpropagation</a></li>
      <li><a href="#to-implement-learning-using-backpropagation">To Implement Learning Using Backpropagation</a></li>
    </ul>
  </li>
</ul>
:ET