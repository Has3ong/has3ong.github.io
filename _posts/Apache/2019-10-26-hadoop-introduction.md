---
title : Hadoop Introduction
tags:
- HDFS
- Hadoop
- NameNode
- DataNode
---

## HDFS (Hadoop Distributed FileSystem)

![image](https://user-images.githubusercontent.com/44635266/67591027-6352bd80-f797-11e9-82e7-7ba8cb1f7a43.png)

1. HDFS는 데이터를 저장하면, 다수의 노드에 복제 데이터도 함께 저장해서 데이터 유실을 방지
2. HDFS에 파일을 저장하거나, 저장된 파일을 조회하려면 스트리밍 방식으로 데이터에 접근해야 함.
3. 한번 저장한 데이터는 수정할 수 없고, 읽기만 가능하게 해서 데이터 무결성을 유지.
4. 데이터 수정은 불가능 하지만 파일이동, 삭제, 복사할 수 있는 인터페이스를 제공함.

## NameNode

네임노드(namenode)는 파일시스템의 네임스페이스를 관리한다. 네임노드는 파일시스템 트리와 그 트리에 포함된 모든 파일과 디렉터리에 대한 메타데이터를 유지한다. 이 정보는 네임스페이스 이미지(namespace image)와 에디트 로그(edit log)라는 두 종류의 파일로 로컬 디스크에 영속적으로 저장된다.

또한, 네임노드는 파일에 속한 모든 블록이 어느 데이터노드에 있는지 파악하고 있다. 하지만 블록의 위치 정보는 시스템이 시작할 때 모든 데이터노드로부터 받아서 재구성하기 때문에 디스크에 영속적으로 저장하지는 않는다. 

## DataNode

데이터노드는 파일시스템의 실질적인 일꾼이다. 데이터노드는 클라이언트나 네임노드의 요청이 있을 때 블록을 저장하고 탐색하며, 저장하고 있는 블록의 목록을 주기적으로 네임노드에 보고한다. 

## Hadoop Server Architecture

![image](https://user-images.githubusercontent.com/44635266/67591755-14a62300-f799-11e9-9df6-fb7db9ed4beb.png)

### 마스터 노드(Master node)

마스터 노드(Master node)는 많은 양의 데이터를 하둡 분산 파일 시스템(HDFS)에 저장하고 맵-리듀스(Map-Reduce)를 통하여 병렬 계산(Parallel computation)을 수행하는 두 가지 핵심 기능을 담당합니다. 잡 트랙커(Jab Tracker)가 맵(Map)과 리듀스(Reduce)를 사용하여 데이터의 병렬 처리(Parallel processing)를 관리하고 조정하는 동안에 네임 노드(Name Node)는 하둡 분산 파일 시스템(HDFS)의 데이터 저장 기능을 관리하고 조정합니다.

### 슬레이브 노드(Slave node)

슬레이브 노드는 머신(Machine)의 대부분을 구성하고 데이터를 저장하고 계산을 실행하는 세부적인 일들을 담당합니다. 각 슬레이브는 서로간에 통신을 하고, 마스터 노드(Master Node)의 지시를 받기 위해서 데이터 노드(Data Node)와 태스크 트랙커(Task Tracker) 데몬을 실행합니다. 태스크 트랙커 데몬(Task Tracker daemon)은 잡 트랙커(Job Tracker)의 슬레이브이며, 데이터 노드 데몬(Data Node daemon)은 네임 노드(Name Node)의 슬레이브입니다.

### 클라이언트 머신(Client machine)

클라이언트 노드는 모든 클러스터 설정(Cluster setting)이 완료된 하둡 시스템(Hadoop System)을 가지고 있지만, 이것은 마스터 노드 또는 슬래이브 노드를 말하는 것은 아닙니다. 클라이언트 머신의 역할은 클러스터에 작업 데이터를 보내어서 맵(Map)과 리듀스(Reduce) 작업을 통하여 데이터를 분석한 후에 완료된 작업 결과를 사용자에게 보여주는 역할을 담당합니다.

> 파일 저장 플로우

![image](https://user-images.githubusercontent.com/44635266/67591071-80878c00-f797-11e9-8c89-79563993c299.png)

1. 어플리케이션이 HDFS 클라이언트에게 파일 저장을 요청하면, HDFS 클라이언트는 네임노드에게 파일 블록들이 저장될 경로 생성을 요청.  네임노드는 해당 파일 경로가 존재하지 않으면 경로를 생성한 후, 다른 클라이언트가 해당 경로를 수정하지 못하도록 락을 검. 그 후, 네임노드는 클라이언트에게 해당 파일 블록들을 저장할 데이터노드의 목록을 반환
2. 클라이언트는 첫 번째 데이터 노드에게 데이터를 전송
3. 첫 번째 데이터 노드는 데이터를 로컬에 저장한 후, 데이터를 두 번째 데이터 노드로 전송
4. 두 번째 데이터 노드는 데이터를 로컬에 저장한 후, 데이터를 세 번째 데이터 노드로 전송
5. 로컬에 데이터를 저장하였으면 자기에게 데이터를 넘겨준 데이터 노드에게, 데이터의 로컬 저장이 완료 되었음을 응답
6. 첫 번째 데이터 노드는 클라이언트에게 파일 저장이 완료 되었음을 응답.

> 파일 읽기 플로우

![image](https://user-images.githubusercontent.com/44635266/67591129-a6149580-f797-11e9-8b13-cfcb6e0f56ad.png)

1. 어플리케이션이 클라이언트에게 파일 읽기를 요청
2. 클라이언트는 네임노드에게 요청된 파일이 어떤 블록에 저장되어 있는지 정보를 요청
3. 메타데이터를 통해 파일이 저장된 블록 리스트를 반환
4. 클라이언트는 데이터 노드에 접근하여 블록 조회 요청
5. 데이터 노드는 클라이언트에게 요청된 블록을 전송
6. 클라이언트를 어플리케이션에 데이터를 전달

