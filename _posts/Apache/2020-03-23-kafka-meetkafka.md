---
title : Meet Kafka
tags :
- Publish/Subscribe Messaging
- Apache
- Kafka
---

*이 포스트는 [Kafka Definitive Guide](https://github.com/Avkash/mldl/blob/master/pages/docs/books/confluent-kafka-definitive-guide-complete.pdf)를 바탕으로 작성하였습니다.*

## Publish/Subscribe Messaging

Kafka 에 대해 알아보기 앞서 **메세지 발행 / 구독(publish / subscribe)** 의 개념을 알아야합니다. 메세지 발행 / 구독 시스템은 데이터를 발행자가 직접 구독자에게 보내지 않습니다.

발행 구독 시스템에 전송하면 구독자가 특정 부류의 메세지를 구독할 수 있게 해줍니다. 이때 발행된 메세지를 저장하고 중계하는 역할을 브로커가 수행합니다.

### How It Starts 

대부분 발행 / 구독 시스템은 간단한 메세지 큐나 프로세스 간 통신 채널을 가지는 형태로 시작됩니다.

예를 들어 메트릭을 전송하는 어플리케이션 서비스를 생성해야 하며, 대시보드 화면에 정보를 보여주는 어플리케이션 서비스와 직접 연결하여 사용합니다.(`Example 1`)

> Example 1 - A single, direct metrics publisher

![image](https://user-images.githubusercontent.com/44635266/70034511-a6a11700-15f4-11ea-91cd-26ca31822975.png)

위 모델은 사용할 수 있는 가장 간단한 방법입니다.

하지만, 더 많은 어플리케이션에서 많은 메세지를 보내기 위해서는 `Example 2` 와 같이 시스템 아키텍처가 복잡한 연결이 될 수 있습니다.

> Example 2 - Many metrics publishers, using direct connections

![image](https://user-images.githubusercontent.com/44635266/77248909-920a8c80-6c80-11ea-8c0c-f9f2ae1f642d.png)

`Example 2` 와 같은 아키텍처는 개선이 필요합니다. 즉, 모든 어플리케이션의 메트릭을 하나의 어플리케이션이 수신하게 하고, 하나의 서버로 제공하면 해당 메트릭이 필요한 어떤 시스템에서도 쉽게 조회할 수 있습니다.

이 경우 `Example 3` 과 같이 복잡하지 않은 아키텍처를 만들 수 있으며, 이상적인 메세지 발행 / 구독 시스템 입니다.

> Example 3 - A metrics publish/subscribe system

![image](https://user-images.githubusercontent.com/44635266/70034515-a86ada80-15f4-11ea-99c5-42aeb14c11c3.png)

### Individual Queue Systems 

로그 메세지도 메트릭과 유사하게 처리가 가능합니다. 예를 들어 `Example 4` 는 세 개의 발행 / 구독 시스템으로 구성된 아키텍처를 보여줍니다.

> Example 4 -  Many metrics publishers, using direct connections

![image](https://user-images.githubusercontent.com/44635266/70034517-a99c0780-15f4-11ea-9136-af10688a616b.png)

`Example 2` 같이 개별적인 연결보다는 훨씬 바람직합니다. 하지만 많은 기능이 중복되어 다수의 메세지 처리 시스템을 유지 관리해야합니다. 또한, 다른 종류의 메세지를 처리하려면 개로운 시스템을 추가해야 합니다.

따라서 일반화된 유형의 메세지 데이터를 발행 / 구독하는 하나의 집중 처리 시스템으로 만들면 유연성이나 확장성 모두 좋아집니다.

## Enter Kafka 

**Apache Kafka**가 그런 문제를 해결하기 위해 설계한 Pub/Sub 시스템이다. Kafka 는 **분산 커밋로그(Distributed Commit Log)**, **분산 스트리밍 플랫폼(Distributed Streaming Platform)** 이라고도 합니다.

카프카의 데이터를 지속해서 자장하고 읽을 수 있으며, 시스템 장애에 대비하고 확장에 따른 성능 저하를 방지하기 위해 데이터 분산 처리될 수 있습니다.

### Messages and Batches 

카프카에 데이터 기본단위는 **메세지(Message)** 입니다. 이것은 데이터베이스의 **행(Row)** **레코드(Record)** 카프카의 메세지 데이터는 **토픽(Topic)** 으로 분류된 **파티션(partition)** 에 수록됩니다.

카프카는 효율성을 위해 여러개의 메세지를 모아 **배치(Batch)** 형태로 파티션에 수록하므로 네트워크로부터 각 메세지를 받아서 처리하는 부담을 줄여줍니다. 즉, 배치의 크기가 클 수록 단위 시간당 처리될 수 있는 메세지는 많지만 각 메시지 전송 시간은 길어집니다. 이외에도 배치에는 데이터 압축이 적용되므로 더 효율적인 데이터 전송과 저장 능력을 제공합니다.

### Schemas 

Kafka 는 메세지를 단순히 Byte 배열로 처리하지만, 내용을 이해하기 쉽도록 메세지의 구조를 나타내는 **스키마(Schema)** 를 사용할 수 있습니다.

그리고 각 어플리케이션의 필요에 따라 메세지 스키마로 여러가지 표준 형식을 사용할 수 있습니다. 가장 간단한 방법으로는 **JSON(Javascript Object Notation)** 이나 **XML(Extensible Markup Language)** 가 있습니다.

하지만, Kafka 와 스키마 버전간의 호환성이 떨어져서, Apache Avro 를 많이 선호합니다. 원래 하둡(Hadoop) 을 위해 개발된 직렬화 프레임워크입니다.

Avro 는 데이터를 직렬화하는 형식을 제공하며, 메세지와는 별도로 스키마를 유지 관리하므로 스키마가 변경되더라도 어플리케이션의 코드를 추가하거나 변경할 필요가 없습니다. 또한, 강력한 데이터 타입을 지원합니다.

Kafka 에서는 일관된 데이터 형식이 중요합니다. 메세지 쓰기와 읽기 작업을 분리해서 할 수 있기 때문입니다. 만일 두 작업이 하나로 합쳐져 있다면 데이터 형식을 병행처리하기 위해 메세지 읽기 어플리케이션이 먼저 업데이트되며, 그 다음에 메세지 쓰기 어플리케이션이 업데이트되어야 합니다. Kafka 에서는 잘 정의된 스키마를 공유 레포지터리에 저장하고 사용할 수 있으므로 어플리케이션 변경 없이 메세지를 처리할 수 있습니다.

### Topics and Partitions 

Kafka 의 메세지는 **토픽(Topic)** 으로 분류되빈다. 토픽은 데이터베이스 테이블이나 파일 시스템의 폴더와 유사합니다. 하나의 토픽은 여러 개의 **파티션(Partition)** 으로 구성됩니다.

메세지는 파티션에 추가되는 형태로만 수록되며, 맨 앞에서 제일 끝까지의 순서로 읽힙니다. 대개 하나의 토픽은 여러개의 파티션을 갖지만, 메세지 처리 순서는 토픽이 아닌 파티션별로 유지관리됩니다. `Example 5` 에서 여러개의 파티션을 가지는 토픽에 대해 알 수 있습니다.

각 파티션은 서로 다른 서버에 분산될 수 있습니다. 즉, 하나의 토픽이 여러 서버에 걸쳐 수평적으로 확장될 수 있음을 의미하므로 단일 서버로 처리할때보다 성능이 우수합니다.

> Example 5 - Representation of a topic with multiple partitions

![image](https://user-images.githubusercontent.com/44635266/70034524-ab65cb00-15f4-11ea-8db0-45ce92d9a625.png)

Kafka 와 같은 시스템의 데이터를 얘기할 때 **스트림(Stream)** 이라는 단어를 많이 사용합니다.

스트림은 파티션의 개수와 상관없이 하나의 토픽 데이터로 간주되며, 데이터를 쓰는 프로듀서, 데이터를 읽는 컨슈머로 이동되는 연속적인 데이터를 나타냅니다.

### Producers and Consumers 

**프로듀서(Producer)** 는 새로운 메세지를 생성하며 발행 / 구독 시스템에서 프로듀서를 발행자 또는 작성자라 합니다. 메세지는 특정 토픽으로 생성되며, 기본적으로 프로듀서는 메세지가 어떤 파티션에 수록되는지 관여하지 않습니다.

**컨슈머(Consumer)** 는 메세지를 읽으며, 발행 / 구독 시스템에서는 컨슈머를 구독자 또는 독자라합니다. 컨슈머는 하나 이상의 토픽을 구독하며 메세지가 생성된 순서로 읽으며, 메세지의 오프셋을 유지하여 읽는 메세지의 위치를 알 수 있습니다.

또 다른 종류의 메타데이터인 오프셋은 지속적으로 증가하는 정숫값이며, 메세지가 생성될 때 Kafka 가 추가해줍니다. 파티션에 수록된 각 메세지는 고유한 오프셋을 가집니다. 그리고 주키퍼(Zookeeper) 나 Kafka 에서 각 파티션에 마지막에 읽은 메세지의 오프셋을 저장하고 있으므로 컨슈머가 메세지 읽기를 중단했다가 다시 시작하더라도 언제든 다음 메세지부터 읽을 수 있습니다. 

컨슈머는 **컨슈머 그룹(Consumer Group)** 의 멤버로 동작합니다. 컨슈머 그룹은 하나 이상의 컨슈머로 구성되며, 한 토픽을 소비하기 위해 같은 그룹의 여러 컨슈머가 함께 동작합니다.

한 토픽의 각 파티션은 하나의 컨슈머만 소비할 수 있습니다. `Example 6` 에서는 하나의 토픽을 세 개의 컨슈머를 갖는 그룹을 보여줍니다. 두 컨슈머가 각각 한 파티션만 소비하며, 나머지 컨슈머는 2 개의 파티션을 소비합니다. 

이처럼 각 컨슈머가 특정 파티션에 대응되는 것을 파티션 소유권이라고 합니다.

> Example 6 - A consumer group reading from a topic

![image](https://user-images.githubusercontent.com/44635266/70034528-ac96f800-15f4-11ea-9e69-cd6a7c65d9f3.png)

위 방법을 사용하면 다량의 메세지를 갖는 토픽을 소비하기 위해 컨슈머를 수평저긍로 확장할 수 있습니다.

### Brokers and Clusters 

하나의 Kafka 서버를 **브로커(Broker)** 라 합니다. 브로커는 프로듀서로부터 메세지를 수신하고 오프셋을 지정한 후 해당 메세지를 디스크에 저장합니다.

Kafka 의 브로커는 **클러스터(Cluster)** 의 일부로 동작하도록 설계되었습니다. 여러개의 브로커가 하나의 클러스터에 포함될 수 있으며, 그 중 하나는 자동으로 선정되는 클러스터 컨트롤러의 기능을 수행합니다.

컨트롤러는 클러스터의 각 브로커에게 담당 파티션을 할당하고 브로커들이 정상적으로 동작하는지 모니터링하는 관리 기능을 맡습니다.

각 파티션은 클러스터의 할 브로커가 소유하며, 그 브로커를 파티션 **리더(Ledaer)** 라고 합ㄴ디ㅏ. 또한, 같은 파티션이 여러 브로커에 지정될 수 있는데, 이떄는 해당 파티션이 **복제(Replication)** 됩니다.(`Example 7`) 이 경우 해당 파티션의 메세지는 중복 저장되지만, 관련 브로커에 장애가 생기면 다른 브로커가 소유권을 인계받아 그 파티션을 처리할 수 있습니다.

> Example 7 - Replication of partitions in a cluster

![image](https://user-images.githubusercontent.com/44635266/70034532-ae60bb80-15f4-11ea-87a4-7c4ce7895ab7.png)

Kafka 의 핵심 기능으로 **보존(Retention)** 이 있습니다. 이것은 일정 기간 메세지를 보존하는 것입니다.

### Multiple Clusters 

Kafka 가 많이 설치되어 사용될 때 다중 클러수터를 고려하면 다음과 같은 장점이 있습니다.

* 데이터 타입에 따라 구분해서 처리할 수 있음
* 보안 요구사항을 분리해서 처리할 수 있음
* 재해 복구를 대비한 다중 데이터센터를 유지할 수 있음

Kakfa 클러스터의 복제 메커니즘은 다중 클러스터가 아닌 단일 클러스터에서만 동작하도록 설계되었습니다.

따라서 다중 클러스터를 지원하기 위해 Apache Kafka 프로젝트에는 **미러메이커(MirrorMaker)** 라는 도구가 포함되어 있습니다. 미러메이커도 Kafka 의 컨슈머와 프로듀서이며, 각 미러메이커는 큐로 상호 연결됩니다. 그리고 하나의 Kafka 클러스터에서 소비된 메세지를 다른 클러스터에서도 사용할 수 있도록 생성합니다.

`Example 8` 에서는 미러메이커를 사용하는 다중 데이터센터 아키텍처의 예를 보여줍니다.

> Example 8 - Multiple datacenter architecture

![image](https://user-images.githubusercontent.com/44635266/77312388-3f46d880-6d45-11ea-81ce-ee712be90815.png)

## Why Kafka? 

메세지 발행 / 구독 시스템은 여러가지 있지만 Kafk 의 장점은 아래와 같습니다.

### Multiple Producers 

여러 클라이언트가 많은 토픽을 사용하거나 같은 토픽을 사용해도 Kafka 는 무리 없이 많은 프로듀서의 메세지를 처리할 수 있습니다.

### Multiple Consumers 

다중 프로듀서와 더불어 Kafka 는 많은 컨슈머가 상호 간섭 없이 어떤 메세지 스트림도 읽을 수 있게 지원합니다. 클라이언트가 특정 메세지를 소비하면 다른 클라이언트에서 그 메세지를 사용할 수 없는 큐 시스템과는 다릅니다. Kafka 컨슈머는 그룹의 멤버가 되어 메세지 스트림을 공유할 수 있습니다.

### Disk-Based Retention 

Kafka 는 다중 컨슈머를 처리할 수 있을 뿐만 아니라 지속해서 메세지를 보존할 수 있습니다. 따라서 컨슈머 어플리케이션이 항상 실시간으로 실행되지 않아도 됩니다.

그리고 컨슈머가 다시 실행되면 중단 시점의 메세지를 처리할 수 있습니다.

### Scalable 

Kafka 는 확장성이 좋아 어떤 크기의 데이터도 쉽게 처리할 수 있습니다.  또한, 동시에 여러 브로커에 장애가 생겨도 정상적으로 처리할 수 있는 **복제 팩터(Replication Factor)** 를 더 큰 값으로 지정하여 구성할 수 있습니다.

### High Performance 

지금까지의 모든 기능이 합쳐져 Kafka 를 고성능의 메세지 발행 / 구독 시스템으로 만들어줍니다. 또한, 프로듀서, 컨슈머, 브로커 모두 대용량의 메세지 스트림을 쉽게 처리할 수 있도록 확장될 수 있으며, 확장도 짧은 시간 내에 가능합니다.

## The Data Ecosystem 

데이터를 처리하기 위해 구축한 환경에는 많은 어플리케이션이 있습니다. 데이터를 읽어서 어디서든 사용할 수 있도록 최종 데이터를 데이터 기반 구조에 전달합니다. 이런 작업은 고유한 컨텐츠와 크기, 용도를 가지는 다양한 유형의 데이터로 처리됩니다. 이것이 메세지 데이터의 처리 흐름입니다.

`Example 9` 에서 볼 수 있듯이, Kafka 는 데이터 생태계의 순환 시스템을 제공합니다. 즉, 모든 클라이언트에 대해 일관된 인터페이스를 제공하면서 데이터 기반 구조의 다양한 멤버 간에 메세지를 전달합니다. 이때 메세지 구조를 정의한 스키마를 시스템에서 제공하면 프로듀서와 컨슈머가 어떤 형태로든 밀접하게 연결되지 않아도 되므로, 비즈니스 용도가 생기거나 없어질 때 관련 컴포넌트만 변경하면 됩니다.

> Example 9 - A big data ecosystem

![image](https://user-images.githubusercontent.com/44635266/77313868-f9d7da80-6d47-11ea-8f0c-d642ed857633.png)