---
title : Kafka Internals
tags :
- Storage
- Request
- Replication
- Apache
- Kafka
---

*이 포스트는 [Kafka Definitive Guide](https://github.com/Avkash/mldl/blob/master/pages/docs/books/confluent-kafka-definitive-guide-complete.pdf)를 바탕으로 작성하였습니다.*

현 포스트에서는 Kafka 유저들에게 유용한 다음 3 가지 주제에 초점을 맞추겠습니다.

* How Kafka replication works
* How Kafka handles requests from producers and consumers
* How Kafka handles storage such as file format and indexes

## Cluster Membership

Kafka에서 사용하는 주키퍼를 알아보겠습니다. 내부적으로 주키퍼는 표준 파일 시스템의 디렉토리처럼 계층적인 트리 구조로 데이터를 저장하고 사용합니다. 데이터를 저장하는 노드를 znode 라 하며, 각 znode 이름 앞에는 `/` 를 붙이고 디렉토리 경로를 사용해서 각 노드의 위치를 식별합니다. 

그리고 이러한 노드 관리는 주키퍼를 사용하는 클라이언트에서 합니다. 예를 들어, 노드 생성 / 삭제, 해당 경로의 노드 존재 여부 확인, 해당 노드의 데이터를 읽거나 쓰기 등 입니다.

각 노드에는 상태와 구성 정보 및 위치 정보등의 데이터만 저장이되어 크기가 **임시노드(ephermeral node)** 와 **영구노드(persistent node)** 로 구분이 됩니다.

> Example 1

![image](https://user-images.githubusercontent.com/44635266/70799570-593f5980-1ded-11ea-92ee-d8caa706d631.png)

임시노드는 노드를 생성한 클라이언트가 연결되어 있을 때 만 존재하며, 연결이 끊어지면 자동으로 삭제됩니다. 영구노드는 클라이언트가 삭제하지 않는 한 계속 보존이됩니다. 또한, 노드의 상태를 모니터링하는 Watch 기능이 존재합니다. 즉, 클라이언트가 특정 노드의 Watch를 설정한 경우 해당 노드가 변경되면 콜백 호출을 통해 클라이언트에게 알려줍니다.

Kafka 에서도 주키퍼를 사용하여 클러스터 멤버인 브로커들의 메타데이터를 유지관리합니다. Kafka 클러스터가 사용하는 주키퍼의 최상위 노드가 `/kafka-main` 이라면 이 노드의 자식들로 `/kafka-main/controller`, `/kafka-main/brokers`, `/kafka-main/config`  가 생성이 됩니다.

`/kafka-main/controller` 에는 Kafka 클러스터의 컨트롤러 정보가 저장되며 `/kafka-main/brokers` 에는 브로커 관련 정보가 저장됩니다. `/kafka-main/config` 에는 토픽의 설정 정보가 저장됩니다.

아래 `Example 2` 은 자식 노드들의 경로를 만든 예시 입니다.

> Example 2

![image](https://user-images.githubusercontent.com/44635266/70797940-019eef00-1de9-11ea-9242-35cb376dd9c2.png)

각각 노드마다 저장하는 데이터가 다릅니다.`/kafka-main/controller` 에는 카프카 클러스터의 정보가 저장됩니다. `/kafka-main/brokers` 에는 브로커 관련 정보가 저장이 됩니다. `/kafka-main/config` 에는 토픽의 설정 정보가 저장이 됩니다.

모든 Kafka 브로커는 고유 식별자를 가지며, 이것은 브로커의 구성 파일에 설정되거나 자동으로 생성된다. 브로커 프로세스는 시작될때마다 주키퍼의 `/brokers/id` 에 임시 노드로 자신의 id를 등록합니다. 만일 중복되는 id를 가지는 브로커를 시작하려고하면 오류가 발생합니다.

그리고 브로커가 추가 혹은 삭제되거나 주키퍼와 연결이 끊어지면, 해당 브로커가 시작될 때 생성되었던 임시 노드는 자동으로 주키퍼에서 삭제됩니다.

브로커가 중단되면 해당 브로커의 주키퍼노드는 삭제됩니다. 그러나 해당 브로커의 ID 는 여전히 다른 데이터 구조에 존재합니다. 각 토픽의 레플리카내역에는 브로커들의 ID 가 포함되어 있습니다. 따라서 중단으로 누락된 브로커 ID 로 완전히 새로 교체한 브로커를 시작시키면, 누락된 브로커에 할당되었던 파티션과 토픽들을 가지고 클러스터에 합류합니다.

## The Controller

컨트롤러는 카프카 브로커 중 하나이며, 일반 브로커의 기능에 추가하여 파티션 리더(Leader) 를 선출하는 책임을 갖는다. 클러스터에서 시작하는 첫 번째 브로커가 컨트롤러가 되며, 이 브로커는 주키퍼의 임시 노드인 `/controller` 를 생성한다. 그리고 다른 브로커들이 시작될 때도 `/controller` 를 생성하려고 시도한다. 그러나  *노드가 이미 존재한다* 라는 예외를 받으므로, `/controller` 노드가 있고 클러스터에도 컨트롤러가 있다는것을 알게되어 모든 브로커들은 `/controller` 노드에 주키퍼의 Watch 를 생성하여 이 노드에 변경이 생기는 것을 알 수 있다. 이런 방법을 통해 클러스터에는 항상 하나의 컨트롤러만 존재한다.

> Example 3

![image](https://user-images.githubusercontent.com/44635266/70804620-48491500-1dfa-11ea-9b5b-9351b736e749.png)

컨트롤러 브로커가 중단되거나 주키퍼와의 연결이 끊어지면 임시 노드인 `/controller` 가 삭제가 됩니다. 이때 해당 클러스터의 다른 브로커들이 주키퍼의 Watch를 통해 그 사실을 알게되고 `/controller` 노드의 생성을 시도합니다. 그리고 그 노드를 첫 번째로 생성한 브로커가 컨트롤러가 됩니다.

컨트롤러는 매번 선출될 때마다 주키퍼로부터 새로운 컨트롤러 세대 번호를 받으며, 나머지 브로커들은 현재의 컨트롤러 세대 번호를 알게됩니다. 따라서 변경 전의 컨트롤러 번호의 메세지는 받게되면 무시하게됩니다.

관련 주키퍼경로를 Watch 하여 특정 브로커가 클러스터를 떠났다는 것을 컨트롤러가 인지하면 브로커가 할당되었던 모든 파티션들에 새로운 리더가 필요하다는것을 알게된다. 그 다음에 컨트롤러는 새로운 리더가 필요한 파티션들을 점검하고 새로 리더가 될 브로커를 결정합니다. 그리고 컨트롤러는 파티션들의 새로운 리더들과 팔로워 들의 정보를 모든 브로커들에게 전송을 합니다.

새로운 브로커가 클러스터에 추가되면 컨트롤러는 컨트롤러는 브로커 ID 를 사용해서 그 브로커의 레플리카로 사용할 브로커가 있는지 확인합니다. 만약 있으면 컨트롤러는 새 브로커와 기존 브로커 모두에게 변경 사항을 알리며, 새 브로커의 레플리카들은 기존 리더들의 메세지를 복제합니다.

## Replication 

**복제(Replication)** 은 Kafka 아키텍처의 핵심 입니다. 복제를 이용하여 서버 노드에 장애가 생길 때 Kafka 가 가용성과 내구성을 보장하는 방법입니다.

Kafka 는 데이터 토픽으로 구성되며, 각 토픽은 여러 파티션에 저장될 수 있다. 또한, 각 파티션은 다수의 리플리카를 가질 수 있습니다. 그리고 각 브로커는 서로 다른 토픽과 파티션에 속하는 수 백개의 복제본을 저장합니다.

레플리카에는 다음과 같이 두 가지 형태가 있습니다.

#### *Leader replica*

파티션은 리더로 지정된 하나의 리플리카를 갖는다. 일관성을 보장하기 위해 모든 프로듀서와 컨슈머의 클라이언트의 요청은 리더를 통해서 처리된다.

#### *Follower replica*

각 파티션의 리더를 제외한 나머지 리플리카를 팔로워라고 한다. 팔로워는 클라이언트 요청을 서비스하지 않는다. 대신에 리더의 메세지를 복제하여 동일하게 유지한다. 그리고 특정 파티션의 리더 리플리카가 중단된 경우에 팔로워 리플리카 중 하나가 새로운 리더로 선출이됩니다.

> Example 4

![image](https://user-images.githubusercontent.com/44635266/70807005-ee4b4e00-1dff-11ea-8683-61128c5d0b17.png)

리더는 팔로어 리플리카 중에 어느 것이 최신의 리더 메세지를 복제하는지 알아야한다. 팔로워들은 리더가 받는 모든 최신 메세지를 복제하려고 한다. 그러나 여러가지 이유로 동기화에 실패할 수도 있습니다.

리더와 동기화를 하기 위해 레플리카들은 리더에게 Fetch 요청을 전송합니다. 이것은 컨슈머가 메세지를 읽기 위해 전송하는 것과 같은 타입의 요청입니다. 그리고 그런 요청의 응답으로 리더는 레플리카들에게 메세지를 전송합니다. Fetch 요청에 레플리카가 다음으로 받기 원하는 메세지의 오프셋이 포함되며, 항상 수신된 순서대로 처리가됩니다.

팔로어 레플리카가 요청한 마지막 오프셋을 살펴보면 복제가 얼마나 지연되고 있는지 리더가 알 수 있습니다. 만약 팔로어 레플리카가 10초 이상 메세지를 복제하지 못했다면, 해당 레플리카는 **동기화되지 않는것(out-sync)** 으로 간주가 됩니다. 이처럼 팔로어 레플리카가 리더를 복제하는 데 실패하면, 리더에 장애가 생겼을 때 해당 레플리카는 더 이상 새로운 리더가 될 수 없습니다.

이와는 반대로, 최신 메세지를 계속 요청하는 팔로어 레플리카를 **동기화 리플리카(in-sync-replica, ISR)** 라고 합니다. 기존 리더가 중단되는 경우 동기화 레플리카만이 리더로 선출될 수 있습니다.

동기화되지 않는다고 간주되기 전에, 팔로어가 비활성 상태가 될 수 있는 지연 시간은 `replica.lag.time.max.ms` 매개변수로 제어할 수 있습니다.

### Preferred Leader

현재 리더에 추가하여 각 파티션은 선호 리더를 갖게됩니다. 이것은 토픽이 생성될 때 각 파티션의 리더엿던 레플리카들을 말합니다. 하나의 토픽은 여러 개의 파티션으로 구성 될 수 있으며, 파티션들을 처음 생성할 때는 여러 브로커가 고르게 파티션을 할당받아 리더가 되므로 이것이 선호되는 리더들이라고 합니다.

결론적으로 선호 리더들이 클러스터의 모든 파티션 리더들일 때는 브로커 간의 파티션 배분이 고르게 됩니다. Kafka 는 `auto.leader.rebalance.enable=true` 로 구성되며 선호 리더 레플리카가 현재 리더가 아닐 경우 동기화 레플리카인지 확인하며, 리더를 선출할 때 선호 리더를 현재 리더로 선출하게됩니다.

## Request Processing

Kafka 브로커가 하는 일은 대부분 클라이언트와 파티션 레플리카 및 컨트롤러부터 파티션 리더에게 전송되는 request 를 처리하는 것입니다. Kafka 는 TCP 로 전송되는 이진 프로토콜을 갖고 있습니다 클라이언트부터 브로커에 전송된 모든 요청은 항상 수신된 순서로 처리됩니다. 따라서 Kafka 가 메세지 큐처럼 동작할 수 있어서 저장되는 메세지의 순서가 보장됩니다.

모든 Request 는 다음 내용을 포함하는 표준 헤더를 갖습니다.

* Request Type
  * 16 bit 정수 형식의 고유 번호다. Kafka 메세지를 쓰는 요청은 Produce 라 하며 ID 값은 0 이다.
  * 메세지 요청은 Fetch라 하며 이것은 ID 값은 1 이다.
* Request Version
  * 프로토콜 API 버전을 나타내는 16 bit 정숫값이다.
  * 서로 다른 프로토콜 버전을 사용하는 Kafka 클라이언트를 브로커가 처리하고 그에 맞춰 응답할 수 있다.
* Correlation ID
  * 사용자가 지정한 32 bit 정수값이다. 
  * 이 값은 응답과 에러 로그에도 표시된다.
* Client ID
  * 사용자가 지정한 문자열 형식의 값이다.
  * NULL 값이 될 수 있다.
  * 요청을 전송한 클라이언트 어플리케이션을 식별하는 데 사용할 수 있다.
  
표준 헤더에 추가하여 요청 타입마다 서로 다른 구조의 데이터를 같이 전송합니다. 예를 들어, Kafka 에 메세지를 쓰는 Produce 요청의 경우에는 토픽 이름과 파티션 ID 및 데이터 등이 포함됩니다.

브로커는 자신이 listening 하는 포트에 대하여 acceptor 스레드를 실행하며, 이 스레드는 연결을 생성하고 processor 스레드가 그 다음을 처리하도록 넘겨줍니다. processor 스레드의 개수는 우리가 구성할 수 있습니다. processor 스레드는 클라이언트 연결로 부터 요청을 받고, 그것을 **요청 큐(request queue)** 에 넣으며, **응답 큐(response queue)** 로부터 응답을 가져와 클라이언트에 전송하는 일을 수행합니다.

가장 많이 사용되는 요청 타입입니다.

* 쓰기 요청(Produce request)
  * 프로듀서가 전송하며 Kafka 브로커에게 쓰려는 메세지를 포함한다.
* 읽기 요청(Fetch request)
  * Kafka 브로커로부터 메세지를 읽을 때 컨슈머와 팔로어 레플리카를 전송한다.
  
> Example 5 - Request processing inside Apache Kafka

![image](https://user-images.githubusercontent.com/44635266/70858798-2495e400-1f4c-11ea-9550-bdbe22a5b7e8.png)

쓰기 요청과 읽기 요청은 모두 파티션의 리더 레플리카에게 전솓되어야 합니다. 특정 파티션의 리더를 갖고 있지 않은 브로커가 해당 파티션의 읽기 요청을 수신할 때도 같은 에러가 발생합니다. Kafka 의 클라이언트들이 쓰기와 읽기 요청을 할 때는 요천 관련 파티션의 리더를 포함하는 브로커에게 요청을 전송해야 합니다.

Kafka 클라이언트는 **메타데이터 요청(metadata request)** 이라는 요청 타입을 사용하는데, 클라이언트가 관심을 갖는 토픽 내역을 포함합니다. 메타데이터 요청에 대한 서버 응답에는 토픽에 존재하는 파티션들, 파티션의 레플리카, 어떤 레플리카의 리더인지 등의 정보가 포함된다. 메타데이터 요청은 어떤 브로커에도 전송이 가능합니다. 왜냐하면 모든 브로커가 메타데이터 캐시를 갖고 있기 때문입니다.

클라이언트는 정보를 캐시에 보존한 후 각 파티션의 올바른 브로커에게 쓰기와 읽기 요청을 전송하는 데 사용합니다. 또한, 메타데이터 요청을 전송하여 정보를 새로 업데이트 해야합니다.

그래야지 새로운 브로커가 추가되었을때처럼 토픽 메타데이터가 변경된 것을 알 수 있기 때문입니다.

> Example 6 - Client routing requests

![image](https://user-images.githubusercontent.com/44635266/70858867-79862a00-1f4d-11ea-98dc-4c0586158f65.png)

### Produce Requests

ack 구성 매개변수에는 메세지를 수신해야 하는 브로커의 수를 설정하며, 설정된 값의 브로커가 모두 메세지를 수신해야 쓰기 성공으로 간주합니다. 프로듀서의 acks 매개변수는 다음 세 가지 중 하나로 설정할 수 있습니다.

* acks = 0
  * 브로커의 수신 응답을 기다리지 않음
* acks = 1
  * 리더만 메세지를 수신하면 됨
* acks = all
  * 모든 레플리카 메세지를 받아야함
  

특정 파티션의 리더 레플리카를 포함하는 브로커가 해당 파티션의 **쓰기 요청(Producer Request)** 을 받으면 다음 사항의 검사를 시작합니다.

1. 데이터를 전송한 하용자가 해당 토픽의 권한이 있나
2. 해당 요청에 지정된 acks 값
3. acks=all 인 경우 메세지를 안전하게 쓰는 데 충분한 동기화 레플리카들이 있나

파티션 리더에 메세지를 쓰면 브로커는 acks 매개변수를 확인하여 0 또는 1 이면 즉시 응답을 전송합니다. all 이면 팔로어 레플리카들이 해당 메세지를 복제했는지 리더가 확인할 때까지 **퍼거토리(purgatory)** 라고 하는 버퍼에 해당 요청을 저장합니다.

### Fetch Requests

브로커는 쓰기 요청을 처리하는 방버과 매우 유사하게 **읽기 요청(Fetch Request)** 을 처리합니다. 클라이언트는 읽기를 원하는 토픽과 파티션 및 오프셋에 있는 메세지들의 읽기 요청을 브로커에게 전송합니다.

클라이언트는 각 파티션마다 브로커가 반환할 수 있는 데이터 크기를 제한할 수 있습니다. 클라이언트는 브로커가 전송한 응답을 저장하는 메모리를 할당해야 하므로 크기 제한이 중요합니다.

각 요청은 파티션 리더에게 전송이 되어야 합니다. 읽기 요청이 올바르게 전송되도록 클라이언트는 메타데이터 요청을 합니다. 리더는 요청을 받은 후 적합한지 검사 후 응답합니다.

요청이 적합하면 클라이언트가 요청에 지정한 제한 크기까지의 메세지들을 브로커가 해당 파티션에서 읽은 후 클라이언트에게 전송합니다. 카프카는 **제로 카피(zero-copy)** 기법을 사용해서 클라이언트에게 메세지를 전송합니다.

Kafka 는 파일의 메세지를 중간 버퍼 메모리에 쓰지 않고 곧바로 네트워크 채널로 전송합니다. 데이터를 클라이언트에게 전송하기 전에 로컬 캐시 메모리에 저장하는 대부분의 데이터베이스와 다릅니다. 제로카피 기법은 메모리부터 데이터를 복사하고 버퍼를 관리하는 부담을 제거하므로 성능이 훨씬 더 향상됩니다.

브로커가 반환할 수 있는 데이터의 상한 크기를 설정하는 것과 더불어, 클라이언트는 반환 데이터의 하한 크기도 설정할 수 있습니다.

이를 통하여 클라이언트와 브로커 간에 데이터를 주고받는 횟수가 줄어들어 부담이 줄어듭니다.

> Example 7 - Broker delaying response until enough data accumulated

![image](https://user-images.githubusercontent.com/44635266/70859137-07fcaa80-1f52-11ea-9c89-1097dc3ad8a9.png)

파티션 리더에 존재하는 모든 데이터를 클라이언트가 읽을 수 있는것은 아닙니다. 대부분의 클라이언트는 동기화 레플리카에 쓴 메세지들만 읽을 수 있습니다. 그리고 파티션 리더는 어떤 메세지들이 어느 레플리카에 복제되었는지 알고있으며, 모든동기화 레플리카들이 메세지들을 쓸때까지 컨슈머에게 전송되지 않습니다.

레플리카에 복제되지 않은 메세지들은 '불안전한' 것으로 간주하기 때문에 위와같이 합니다. 리더가 중단되어도 다른 레플리카 리더가 선출되면, 모든 레플리카에 복제되지 않은 메세지들은 더 이상 Kafka 에 존재하지 않게됩니다. 또한 리더에만 존재하는 메세지들을 클라이언트가 읽게하면 일관성이 결여될 수 있습니다.

예를 들어 컨슈머가 아직 복제되지 않은 메세지를 읽은 후 리더가 중단이되면, 해당 메세지를 갖는 브로커가 없으므로 그 메세지는 사라집니다. 그리고 다른 컨슈머들도 그 메세지를 읽을 수 없어 컨슈머의 일관성이 결여됩니다.

따라서 `Example 8` 와 같이 모든 동기화 레플리카가 해당 메세지를 복제할 때까지 기다렸다가 복제된 다음 컨슈머가 읽게 하는것입니다.

> Example 8 - Consumers only see messages that were replicated to in-sync replicas

![image](https://user-images.githubusercontent.com/44635266/70859140-0e8b2200-1f52-11ea-9ea8-53705691c275.png)

### Other Requests 

Kafka 브로커들 간에 사용하는 요청들이 있습니다. 이것들은 내부적인 것이라 클라이언트에서 사용하지 않습니다. 예를 들어, 특정 파티션이 새로운 리더를 갖는다는 것을 컨트롤러가 알릴 때는 새 리더와 팔로어들에게 LeaderAndIsr 요청을 전송합니다. 이제부터는 클라이언트 요청을 받아야 한다는 것을 새로운 리더가 알아야 하고, 팔로워들은 새 리더를 복제해야 한다는 것을 알아야 하기 때문입니다.

## Physical Storage

Kafka 의 기본적인 Storage 단위는 파티션 레플리카입니다. 하나의 파티션은 여러 브로커로 분할될 수 없어 하나의 파티션 크기는 단일 마운트 포인트에 사용 가능한 공간으로 제한 됩니다.

Kafka 를 구성할 때 관리자는 파티션이 저장될 디렉터리 내역을 `log.dirs` 매개변수에 지정합니다.

### File Management

**보존(retention)** 은 Kafka 에서 중요한 개념입니다. Kafka 는 데이터를 영원히 보존하지 않으며, 메세지 삭제 전에 모든 컨슈머가 읽기를 기다리지도 않습니다. 대신 Kafka 관리자는 다른 두 가지 중 하나로 보존 구성을 설정 할 수 있습니다.

1. 메세지를 삭제하기 전 보존하는 시간
2. 오래된 메세지의 제거 전 보존할 데이터 크기

큰 파일에서 제거해야 하는 메세지를 찾아 파일 일부분을 삭제하는 것은 시간이 많이 소요되고 에러도 날 수 있습니다. 따라서 Kafka 에서는 파티션을 **세그먼트(segment)** 로 나눕니다. 각 세그먼트는 최대 1GB 의 데이터 또는 1주일 동안 데이터를 보존합니다. Kafka 에서 데이터를 쓸 때 세그먼트의 제한 크기나 보존 기간에 도달하면 해당 파일을 닫고 새로운 세그먼트 파일에 씁니다.

메세지를 쓰기 위해 사용진 세그먼트를 **액티브 세그먼트(Active Segment)** 라고 합니다. 액티브 세그먼트는 삭제되지 않습니다. 따라서 로그 보존기간은 1일, 각 세그먼트는 5일 동안 보존하게 설정하면, 데이터는 5일동안 보존된다. 세그먼트 파일이 닫혀여만 삭제할 수 있다. 만약 1주 동안 데이터를 보존하게 하고 매일 하나의 새로운 세그먼트를 생성하면 7개의 세그먼트를 가진다.

### File Format

각 세그먼트는 하나의 데이터 파일로 생성되며, Kafka 메세지와 Offset 이 저장됩니다. 그리고 디스크에 수록되는 데이터의 형식은 메세지 형식과 동일합니다. 이처럼 디스크와 네트워크 모두 같은 메세지 형식을 사용하므로, 카프카는 제로카피 기법을 사용해 메세지 전송을 최적화 할 수 있습니다. 즉, 컨슈머에게 메세지를 전송할 때 별도의 버퍼 메모리를 사용하지 않고 디스크에서 바로 네트워크로 전송하며, 프로듀서가 이미 압축해서 전송한 메세지의 압축 해지와 재압축을 하지 않아도 됩니다.

키와 값 및 오프셋에 추가하여 각 메세지는 메세지 크기, checksum code, 메세지 형식의 버전을 나타내는 매직 바이트, 압축 코덱, 타임스탬프 등을 포함바니다. Kafka 구성에 따라 타임 스탬프는 메세지가 전송될 때 프로듀서가 지정하거나 메세지가 수신될 때 브로커가 지정한다.

프로듀서가 압축된 메세지를 전송하면, 하나의 배치에 포함된 모든 메세지가 같이 압축되어 *wrapper message* 의 *value* 로 전송됩니다. `(Example 9)` 그러면 브로커가 하나의 메세지를 수신하고, 컨슈머에도 아래와 같이 전송이 됩니다. 컨슈머가 해당 메세지의 값의 압축을 풀면 배치에 포함된 모든 메세지를 알 수 있습니다.

> Example 9 -  A normal message and a wrapper message

![image](https://user-images.githubusercontent.com/44635266/70889320-ad348300-2025-11ea-923a-fedfddbcad62.png)

프로듀서가 압축을 사용하면 더 큰 배치를 전송해도 네트워크와 브로커 디스크 모두에서 유리합니다. 단, 컨슈머가 사용하는 메세지 형식을 변경하는 경우에는 전송 프로토콜과 디스크 수록 형식 모두 변경해야 합니다. 업그레이드로 인해 두 가지 형식을 갖게 된 메세지들을 포함하는 파일 처리 방법을 브로커도 알아야 합니다.

브로커는 *DumpLogSegment* 도구와 함께 배포됩니다. 이것을 사용하면 파일 시스템에서 파티션 세그먼트와 내용을 자세히 살펴 볼 수 있습니다

실행 방법은 아래와 같습니다.

```shell
$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments
```

여기서 `--deep-iteration` 매개변수를 추가하면 래퍼 메세지 내부에 압축된 메세지 정보를 보여줍니다.

### Indexes

Kafka 는 컨슈머가 특정 오프셋부터 메세지를 읽을 수 있게 해줍니다. 예를 들어, 컨슈머가 오프셋 100 에 시작하는 1 MB 메세지를 요청하면, 브로커가 오프셋 100 의 메세지를 빨리 찾아 그 오프셋부터 메세지를 읽기 시작한다. 이때 지정된 오프셋의 메세지를 브로커가 빨리 찾을 수 있도록 Kafka 는 **인덱스(index)** 를 유지관리하며, 인덱스는 세그먼트 파일과 파일 내부 위치로 오프셋과 연관시킨다.

인덱스도 세그먼트로 분할이 됩니다. 메세지가 삭제되면 연관된 인덱스 항목도 삭제할 수 있습니다. Kafka 에서는 인덱스의 체크섬을 유지 관리하지 않습니다. 만약 인덱스가 손상되면 연관된 로그 세그먼트로부터 메세지를 다시 읽고 오프셋과 위치를 수록하여 다시 생성합니다.

### Compaction

Kafka 는 토픽 보존 정책을 사용하여 **삭제 보존 정책**, **압축 보존 정책** 을 모두 지원합니다. 삭제 보존 정책은 보존 기간 이전의 메세지를 삭제하며 압축 보존 정책은 각 키의 가장 최근 값만 토픽에 저장할 수 있습니다.

압축 보존 정책은 키와 값을 갖는 메세지를 생성하는 어플리케이션의 토픽에만, 적용되며, 토픽의 null 키가 포함되며 압축이 안됩니다.

### How Compaction Works

키와 값의 형태로 된 메세지를 수록하는 각 로그 세그먼트는 아래 `Example 10` 와 같이 다음의 두 부분으로 나누어 생각할 수 있습니다.

* Clean
  * 이전에 압축되었던 메세지들이 있다.
  * 각 키에 대해 하나의 값만 포함하며, 이것은 이전에 압축할 당시의 가장 최근 값이다.
* Dirty
  * 직전 압축 이후에 추가로 쓴 메세지들이 저장되는 부분

> Example 10 - Partition with clean and dirty portions

![image](https://user-images.githubusercontent.com/44635266/70889678-8034a000-2026-11ea-994d-dbe779e9cd6a.png)

Kafka 가 시작될 때 압축이 활성화 되면 각 브로커는 하나의 압축 매니저 스레드와 여러 개의 압축 스레드를 시작시킨다. 이 스레드들은 압축 작업을 수행하는 책임을 가지며 각 스레드는 전체 파티션 크기보다 더티 메세지의 비율이 가장 큰 파티션을 선택하고 압축합니다.

파티션을 압축하기 위해 압축 스레드는 더티 메세지들을 읽어서 메모리에 압축용 오프셋 Map 을 생성합니다. 오프셋 Map 의 각 항목은 키(16 byte hash value) 와 값(8 byte) 로 구성되빈다. 따라서 각 항목은 24 byte 메모리만 사용됩니다.

예를들어, 각 세그먼트 크기는 1 GB 이며 세그먼트의 각 메세지 크기는 1 KB 라 가정한다면, 이 세그먼트는 100 만 개의 메세지를 갖는다. 따라서 이 세그먼트를 압축하기 위해 필요한 오프셋 Map 은 24 MB 면 됩니다. 그러나 실제로 이보다 적을 수 있습니다. 같은 키를 갖는 메세지들이 많아지면 메세지 키의 해시 값을 키로 사용하는 오프셋 Map의 항목 수도 적어질 것이기 때문입니다.

Kafka를 구성할 때 관리자는 오프셋 Map 에 사용할 메모리를 설정합니다. 이것은 각 압축 스레드가 따로 가질 수 있는 오프셋 Map의 크기를 합한 전체 메모리 입니다.

예를 들어, 오프셋 Map 을 1 GB 로 구성하고 5 개의 압축 스레드를 사용한다면, 각 스레드는 200 MB 의 Map 을 따로 가질 수 있습니다. 또한 파티션의 더티 부분 전체가 Map 에 다 들어가지 않아도 되지만, 최소한 하나의 세그먼트는 Map 의 크기에 맞게 들어가야합니다. 그렇지 않으면 Kafka 가 에러를 발생시키므로, 관리자가 Map 의 메모리를 늘리거나 압축 스레드의 개수를 줄여서 사용해야합니다. 만약 소수의 세그먼트만 Map 에 들어간다면, Kafka 가 시작될 때 가장 오래된 세그먼트들부터 압축하여 Map 에 넣습니다. 그 외의 나머지 세그먼트들은 더티 부분에 남아있다가 다음 번 압축을 기다립니다.

압축 스레드가 오프셋 Map 을 생성한 다음에는 파티션의 클린 부분 세그먼트들을 가장 오래된 것부터 읽으면서 해당 세그먼트의 각 메세지 키가 오프셋 Map 에 있는지 확인합니다. 만약 키가 오프셋 Map 에 없으면 방금 읽은 메세지의 값이 가장 최근 것이므로 해당 메세지를 대체 세그먼트로 복사합니다. 그렇지 않고 키가 오프셋 Map 에 있으면 해당 메세지는 제외합니다. 왜냐하면 같은 메세지 키를 가진 새로운 값이 파티션에 있기 떄문입니다. 그리고 세그먼트의 모든 처리가 끝나면 원래 세그먼트를 대체 세그먼트로 교체하고 다음 세그먼트를 계속 처리합니다. 모든 작업이 끝나면 같은 키를 가지는 메세지는 하나만 남게되고 가장 최근 값은 가지게 됩니다.`(Example 11)`

> Example 11 - Partition segment before and after compaction

![image](https://user-images.githubusercontent.com/44635266/70890491-89bf0780-2028-11ea-81cf-7c6eb093487f.png)

### Deleted Events

가장 최근 메세지조차 남기지 않고 시스템에 특정 키를 완전히 삭제할 때는 어플리케이션에서 해당 키와 null 값을 포함하는 메세지를 카프카에 쓰면 됩니다. 그러면 압축 스레드에서 그런 메세지를 발견할 때 평상시 대로 압축을 수행한 후 키에 대해서는 null 값을 갖는 메세지만 남겨둘 것입니다. 그리고 **톰스톤(tombstone)** 이라 하는 이런 특별한 메세지는 Kafka 에 설정된 기간 동안 보존될것이다.

또한, 이 기간 동안 컨슈머가 톰스톤 메세지를 읽으면 값이 null 이라 삭제되었음을 알 수 있으므로, 이와 관련된 데이터를 RDB 에 저장한다면 거기에서 해당 사용자를 삭제해야 한다는것도 알 수 있습니다. 그리고 Kafka 에 설정된 시간이 지나면 압축 스레드에서 톰스톤 메세지를 삭제할 것이고, 해당 키의 메세지는 파티션에서 없어질것입니다.

단, 이때 컨슈머가 톰스톤 메세지를 인식하기에 충분한 시간을 주어야 합니다. 왜냐하면 만에 하나 컨슈머가 여러시간 동안 중단되어 톰스톤 메세지가 누락된다면 해당 키를 알지 못할것이고, 이로 인해 Kafka 에서 삭제된것인지 또는 컨슈머의 DB 에서 삭제해야 하는지 알 수 없기 때문입니다.

### When Are Topics Compacted?

Kafka 에서는 현재 사용 중인 세그먼트가 아닌 사용 중이 아닌 세그먼트의 메세지들만 압축 대상이 됩니다.

압축은 토픽의 읽고 쓰기 성능에 영향을 줄 수 있으므로 너무 자주하지 않는것이 좋습니다. 하지만 디스크 공간을 차지하므로 너무 많은 더티 레코드를 남겨두지 않는것이 좋기 때문에 더티 레코드가 토픽의 50 % 에 해당하는 디스크 공간을 사용할 때 압축을 하는 것이 합리적으로 비입니다. 이 비율은 관리자가 조정할 수 있습니다.