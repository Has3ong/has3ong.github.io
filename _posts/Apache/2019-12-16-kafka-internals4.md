---
title : Apache Kafka Internals -4-
tags :
- Kafka
- APache
---

*이 포스트는 [Kafka Definitive Guide](https://github.com/Avkash/mldl/blob/master/pages/docs/books/confluent-kafka-definitive-guide-complete.pdf)를 바탕으로 작성하였습니다.*

## Physical Storage

Kafka 의 기본적인 Storage 단위는 파티션 레플리카입니다. 하나의 파티션은 여러 브로커로 분할될 수 없어 하나의 파티션 크기는 단일 마운트 포인트에 사용 가능한 공간으로 제한 됩니다.

Kafka 를 구성할 때 관리자는 파티션이 저장될 디렉터리 내역을 log.dirs 매개변수에 지정합니다.

### File Management

**보존(retention)** 은 Kafka 에서 중요한 개념입니다. Kafka 는 데이터를 영원히 보존하지 않으며, 메세지 삭제 전에 모든 컨슈머가 읽기를 기다리지도 않습니다. 대신 Kafka 관리자는 다른 두 가지 중 하나로 보존 구성을 설정 할 수 있습니다.

1. 메세지를 삭제하기 전 보존하는 시간
2. 오래된 메세지의 제거 전 보존할 데이터 크기

큰 파일에서 제거해야 하는 메세지를 찾아 파일 일부분을 삭제하는 것은 시간이 많이 소요되고 에러도 날 수 있습니다. 따라서 Kafka 에서는 파티션을 **세그먼트(segment)** 로 나눕니다. 각 세그먼트는 최대 1GB 의 데이터 또는 1주일 동안 데이터를 보존합니다. Kafka 에서 데이터를 쓸 때 세그먼트의 제한 크기나 보존 기간에 도달하면 해당 파일을 닫고 새로운 세그먼트 파일에 씁니다.

메세지를 쓰기 위해 사용진 세그먼트를 **액티브 세그먼트(Active Segment)** 라고 합니다. 액티브 세그먼트는 삭제되지 않습니다. 따라서 로그 보존기간은 1일, 각 세그먼트는 5일 동안 보존하게 설정하면, 데이터는 5일동안 보존된다. 세그먼트 파일이 닫혀여만 삭제할 수 있다. 만약 1주 동안 데이터를 보존하게 하고 매일 하나의 새로운 세그먼트를 생성하면 7개의 세그먼트를 가진다.

### File Format

각 세그먼트는 하나의 데이터 파일로 생성되며, Kafka 메세지와 Offset 이 저장됩니다. 그리고 디스크에 수록되는 데이터의 형식은 메세지 형식과 동일합니다. 이처럼 디스크와 네트워크 모두 같은 메세지 형식을 사용하므로, 카프카는 제로카피 기법을 사용해 메세지 전송을 최적화 할 수 있습니다. 즉, 컨슈머에게 메세지를 전송할 때 별도의 버퍼 메모리를 사용하지 않고 디스크에서 바로 네트워크로 전송하며, 프로듀서가 이미 압축해서 전송한 메세지의 압축 해지와 재압축을 하지 않아도 됩니다.

키와 값 및 오프셋에 추가하여 각 메세지는 메세지 크기, checksum code, 메세지 형식의 버전을 나타내는 매직 바이트, 압축 코덱, 타임스탬프 등을 포함바니다. Kafka 구성에 따라 타임 스탬프는 메세지가 전송될 때 프로듀서가 지정하거나 메세지가 수신될 때 브로커가 지정한다.

프로듀서가 압축된 메세지를 전송하면, 하나의 배치에 포함된 모든 메세지가 같이 압축되어 *wrapper message* 의 *value* 로 전송됩니다. `(Example 1)` 그러면 브로커가 하나의 메세지를 수신하고, 컨슈머에도 아래와 같이 전송이 됩니다. 컨슈머가 해당 메세지의 값의 압축을 풀면 배치에 포함된 모든 메세지를 알 수 있습니다.

> Example 1 -  A normal message and a wrapper message

![image](https://user-images.githubusercontent.com/44635266/70889320-ad348300-2025-11ea-923a-fedfddbcad62.png)

프로듀서가 압축을 사용하면 더 큰 배치를 전송해도 네트워크와 브로커 디스크 모두에서 유리합니다. 단, 컨슈머가 사용하는 메세지 형식을 변경하는 경우에는 전송 프로토콜과 디스크 수록 형식 모두 변경해야 합니다. 업그레이드로 인해 두 가지 형식을 갖게 된 메세지들을 포함하는 파일 처리 방법을 브로커도 알아야 합니다.

브로커는 *DumpLogSegment* 도구와 함께 배포됩니다. 이것을 사용하면 파일 시스템에서 파티션 세그먼트와 내용을 자세히 살펴 볼 수 있습니다

실행 방법은 아래와 같습니다.

```shell
$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments
```

여기서 `--deep-iteration` 매개변수를 추가하면 래퍼 메세지 내부에 압축된 메세지 정보를 보여줍니다.

### Indexes

Kafka 는 컨슈머가 특정 오프셋부터 메세지를 읽을 수 있게 해줍니다. 예를 들어, 컨슈머가 오프셋 100에 시작하는 1MB 메세지를 요청하면, 브로커가 오프셋 100의 메세지를 빨리 찾아 그 오프셋부터 메세지를 읽기 시작한다. 이때 지정된 오프셋의 메세지를 브로커가 빨리 찾을 수 있도록 Kafka 는 **인덱스(index)** 를 유지관리하며, 인덱스는 세그먼트 파일과 파일 내부 위치로 오프셋과 연관시킨다.

인덱스도 세그먼트로 분할이 됩니다. 메세지가 삭제되면 연관된 인덱스 항목도 삭제할 수 있습니다. Kafka 에서는 인덱스의 체크섬을 유지 관리하지 않습니다. 만약 인덱스가 손상되면 연관된 로그 세그먼트로부터 메세지를 다시 읽고 오프셋과 위치를 수록하여 다시 생성합니다.