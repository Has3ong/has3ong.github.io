---
title : Apache Kafka Internals -5-
tags :
- Compaction
- Kafka
---

*이 포스트는 [Kafka Definitive Guide](https://github.com/Avkash/mldl/blob/master/pages/docs/books/confluent-kafka-definitive-guide-complete.pdf)를 바탕으로 작성하였습니다.*

## Compaction

Kafka 는 토픽 보존 정책을 사용하여 **삭제 보존 정책**, **압축 보존 정책** 을 모두 지원합니다. 삭제 보존 정책은 보존 기간 이전의 메세지를 삭제하며 압축 보존 정책은 각 키의 가장 최근 값만 토픽에 저장할 수 있습니다.

압축 보존 정책은 키와 값을 갖는 메세지를 생성하는 어플리케이션의 토픽에만, 적용되며, 토픽의 null 키가 포함되며 압축이 안됩니다.

### How Compaction Works

키와 값의 형태로 된 메세지를 수록하는 각 로그 세그먼트는 아래 `Example 2` 와 같이 다음의 두 부분으로 나누어 생각할 수 있습니다.

* Clean
  * 이전에 압축되었던 메세지들이 있다.
  * 각 키에 대해 하나의 값만 포함하며, 이것은 이전에 압축할 당시의 가장 최근 값이다.
* Dirty
  * 직전 압축 이후에 추가로 쓴 메세지들이 저장되는 부분

> Example 2 - Partition with clean and dirty portions

![image](https://user-images.githubusercontent.com/44635266/70889678-8034a000-2026-11ea-994d-dbe779e9cd6a.png)

Kafka 가 시작될 때 압축이 활성화 되면 각 브로커는 하나의 압축 매니저 스레드와 여러 개의 압축 스레드를 시작시킨다. 이 스레드들은 압축 작업을 수행하는 책임을 가지며 각 스레드는 전체 파티션 크기보다 더티 메세지의 비율이 가장 큰 파티션을 선택하고 압축합니다.

파티션을 압축하기 위해 압축 스레드는 더티 메세지들을 읽어서 메모리에 압축용 오프셋 Map 을 생성합니다. 오프셋 Map 의 각 항목은 키(16byte hash value) 와 값(8byte) 로 구성되빈다. 따라서 각 항목은 24 byte 메모리만 사용됩니다.

예를들어, 각 세그먼트 크기는 1GB 이며 세그먼트의 각 메세지 크기는 1KB 라 가정한다면, 이 세그먼트는 100만 개의 메세지를 갖는다. 따라서 이 세그먼트를 압축하기 위해 필요한 오프셋 Map 은 24MB 면 됩니다. 그러나 실제로 이보다 적을 수 있습니다. 같은 키를 갖는 메세지들이 많아지면 메세지 키의 해시 값을 키로 사용하는 오프셋 Map의 항목 수도 적어질 것이기 때문입니다.

Kafka를 구성할 때 관리자는 오프셋 Map 에 사용할 메모리를 설정합니다. 이것은 각 압축 스레드가 따로 가질 수 있는 오프셋 Map의 크기를 합한 전체 메모리 입니다.

예를 들어, 오프셋 Map 을 1GB 로 구성하고 5개의 압축 스레드를 사용한다면, 각 스레드는 200MB 의 Map을 따로 가질 수 있습니다. 또한 파티션의 더티 부분 전체가 Map 에 다 들어가지 않아도 되지만, 최소한 하나의 세그먼트는 Map의 크기에 맞게 들어가야합니다. 그렇지 않으면 Kafka 가 에러를 발생시키므로, 관리자가 Map 의 메모리를 늘리거나 압축 스레드의 개수를 줄여서 사용해야합니다. 만약 소수의 세그먼트만 Map 에 들어간다면, Kafka 가 시작될 때 가장 오래된 세그먼트들부터 압축하여 Map 에 넣습니다. 그 외의 나머지 세그먼트들은 더티 부분에 남아있다가 다음 번 압축을 기다립니다.

압축 스레드가 오프셋 Map 을 생성한 다음에는 파티션의 클린 부분 세그먼트들을 가장 오래된 것부터 읽으면서 해당 세그먼트의 각 메세지 키가 오프셋 Map에 있는지 확인합니다. 만약 키가 오프셋 Map 에 없으면 방금 읽은 메세지의 값이 가장 최근 것이므로 해당 메세지를 대체 세그먼트로 복사합니다. 그렇지 않고 키가 오프셋 Map 에 있으면 해당 메세지는 제외합니다. 왜냐하면 같은 메세지 키를 가진 새로운 값이 파티션에 있기 떄문입니다. 그리고 세그먼트의 모든 처리가 끝나면 원래 세그먼트를 대체 세그먼트로 교체하고 다음 세그먼트를 계속 처리합니다. 모든 작업이 끝나면 같은 키를 가지는 메세지는 하나만 남게되고 가장 최근 값은 가지게 됩니다.`(Example 3)`

> Example 3 - Partition segment before and after compaction

![image](https://user-images.githubusercontent.com/44635266/70890491-89bf0780-2028-11ea-81cf-7c6eb093487f.png)

### Deleted Events

가장 최근 메세지조차 남기지 않고 시스템에 특정 키를 완전히 삭제할 때는 어플리케이션에서 해당 키와 null 값을 포함하는 메세지를 카프카에 쓰면 됩니다. 그러면 압축 스레드에서 그런 메세지를 발견할 때 평상시 대로 압축을 수행한 후 키에 대해서는 null 값을 갖는 메세지만 남겨둘 것입니다. 그리고 **톰스톤(tombstone)** 이라 하는 이런 특별한 메세지는 Kafka 에 설정된 기간 동안 보존될것이다.

또한, 이 기간 동안 컨슈머가 톰스톤 메세지를 읽으면 값이 null 이라 삭제되었음을 알 수 있으므로, 이와 관련된 데이터를 RDB 에 저장한다면 거기에서 해당 사용자를 삭제해야 한다는것도 알 수 있습니다. 그리고 Kafka 에 설정된 시간이 지나면 압축 스레드에서 톰스톤 메세지를 삭제할 것이고, 해당 키의 메세지는 파티션에서 없어질것입니다.

단, 이때 컨슈머가 톰스톤 메세지를 인식하기에 충분한 시간을 주어야 합니다. 왜냐하면 만에 하나 컨슈머가 여러시간 동안 중단되어 톰스톤 메세지가 누락된다면 해당 키를 알지 못할것이고, 이로 인해 Kafka 에서 삭제된것인지 또는 컨슈머의 DB 에서 삭제해야 하는지 알 수 없기 때문입니다.

### When Are Topics Compacted?

Kafka 에서는 현재 사용 중인 세그먼트가 아닌 사용 중이 아닌 세그먼트의 메세지들만 압축 대상이 됩니다.