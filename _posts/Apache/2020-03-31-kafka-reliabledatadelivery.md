---
title : Kafka Reliable Data Delivery
tags :
- Reliable System
- Broker
- Replication
- Apache
- Kafka
---

*이 포스트는 [Kafka Definitive Guide](https://github.com/Avkash/mldl/blob/master/pages/docs/books/confluent-kafka-definitive-guide-complete.pdf)를 바탕으로 작성하였습니다.*

## Reliability Guarantees 

신뢰성을 얘기할 때 우리는 **보장(guarantee)** 을 거론합니다. 

가장 많이 알려진 신뢰성 보장은 ACID 입니다. RDB 가 보편적으로 지원하는 표준화된 신뢰성 보장입니다. ACID 는 **원자성(Atomicity) ,일관성(Consistency), 고립성(Isolation), 지속성(Durability)** 을 의미합니다. 따라서 어떤 데이터베이스가 ACID 를 준수한다면 그것은 트랜잭션 처리와 관련된 약속된 행동을 보장한다는 의미입니다.

이런 보장이 있기 때문에 어플리케이션에서 RDB 를 믿고 사용할 수 있습니다. 그렇다면 Kafka 에서는 무엇을 보장하는지 알아보겠습니다.

1. Kafka 에서는 파티션의 메세지 순서를 보장합니다.
2. 각 파티션의 모든 ISR 에 메세지를 썻다면 해당 메세지는 커밋된 것으로 간주한다.
3. 최소 하나의 레플리카가 살아있다면 커밋된 메세지는 유실되지 않는다.
4. 컨슈머는 커밋된 메세지만 읽을 수 있다.

신뢰성 있는 시스템을 만들기 위해서는 트레이드오프가 수반됩니다. 따라서 Kafka 는 관리자와 개발자들이 필요한 신뢰성의 정도를 조절할 수 있게 개발되었습니다.

신뢰도가 높고 지속적으로 메세지를 저장하는 것의 중요도와 가용성, 높은 처리량, 낮은 지연 시간 하드웨어 비용의 중요도 중 어느것에 더 큰 비중을 둘 것인지 알 수 있습니다.

## Replication 

파티션마다 다수의 레플리카를 가질 수 있는 Kafka 의 복제 매커니즘은 신뢰성 보장의 핵심입니다. 장애 발생시 Kafka 가 메세지의 지속성을 제공하는 방법이 다수의 레플리카에 메세지를 쓰는 것이기 때문입니다.

Kafka 의 각 토픽은 데이터를 저장하는 기본 요소인 파티션으로 분할되며, 각 파티션은 하나의 디스크에 저장됩니다. Kafka 는 파티션 내부의 메세지 순서를 보장하며, 파티션은 온라인 또는 오프라인이 될 수 있습니다. 각 파티션은 다수의 레플리카를 가질 수 있으며, 레플리카 중 하나는 리더로 지명되며, 모든 메세지는 리더 레플리카에 쓰거나 읽습니다. 이외의 다른 레플리카들은 팔로워라하며, 리더와 동기화되면서 떄에 맞춰 최근의 모든 메세지를 복제합니다. 만일 리더를 사용할 수 없게 되면 동기화된 레플리카 중 하나가 리더가됩니다.

레플리카가 파티션의 리더이거나 다음과 같은 팔로워일때 그 레플리카는 동기화되는것으로 간주됩니다.

1. 주키퍼와 세션이 열결되어 있음. 즉, 최근 6 초 내에 주키퍼에게 하트비트를 전송했음을 의미
2. 최근 10초 내에 리더로부터 메세지를 읽었음

만일 위 두 사항을 만족하지 않으면 동기화 되지 않는 것으로 간주하여 Zookeeper 와 다시 연결되어 리더에 저장된 가장 최근 메세지드띾지 복제하면 동기화 상태가 됩니다.

동기화에 약간 뒤쳐진 동기화 레플리카는 프로듀서와 컨슈머의 처리 속도를 저하할 수 있습니다. 메세지가 커밋되기 전에 모든 동기화 레플리카의 메세지 수신을 기다리기 때문입니다. 하지만, 레플리카가 동기화되지 않은 상태면 메세지 수신을 기다리지 않습니다. 이 경우 레플리카는 여전히 동기화가 뒤쳐지겠지만 프로듀서와 컨슈머의 처리 성능에는 영향을 주지 않습니다.

## Broker Configuration 

신뢰성이 중요한 토픽과 신뢰성보다는 다른 관점이 더 중요한 토픽 모두를 Kafka 클러스터에 저장할 수 있습니다. Kafka 에서는 토픽마다 신뢰성에 관련된 트레이드오프를 제어할 수 있기 떄문입니다.

### Replication Factor 

토픽 수준에서 **복제 펙터(replication factor)** 를 구성하는 매개변수는 `replication.factor` 입니다. 브로커 수준에서는 자동 생성되는 토픽에 대해 `default.replication.factor` 매개변수를 설정할 수 있습니다.

복제 팩터가 N 이면 N-1 개의 브로커가 중단되더라도 여전히 토픽의 데이터를 신뢰성 있게 읽거나 쓸 수 있습니다. 따라서 복제 팩터가 클수록 가용성과 신뢰성은 높아지고 장애에 따른 데이터 유실은 적어집니다. 반면에, 복제 팩터가 N 일 경우 최소한 N 개의 브로커가 필요하고 N 개의 복사본을 저장해야 하므로 N 배의 디스크 공간이 필요합니다. 그러므로 가용성을 높이는 대신 하드웨어가 많이 소요됩니다.

보통 가용성이 중요한 토픽은 복제 팩터를 3 으로 설정할 것은 권장합니다.

레플리카들의 위치도 매우 중요합니다. 기본적으로 Kafka 는 파티션의 각 레플리카들을 별개의 브로커에 설정합니다. 하지만, 파티션의 모든 레플리카들이 같은 랙에 있는 브로커들에 속해있는 경우 랙이 오작동하면 복제 팩터와는 무관하게 파티션의 가용성을 상실합니다. 따라서 랙 수준의 장애를 방지하기 위해 다수의 랙에 브로커드들을 위치시킨 후 브로커 구성 매개변수인 `broker.rack` 을 사용해 각 브로커의 랙 이름을 설정할 것은 권장합니다.

### Unclean Leader Election 

이 구성은 브로커 수준에서만 사용할 수 있습니다. 매개변수 이름은 `unclean.leader.election.enable` 이며 기본값은 true 입니다.

파티션의 리더를 더 이상 사용할 수 없다면 동기화 레플리카 중 하나가 새로운 리더가 선출됩니다. 이 경우 데이터가 유실되지 않는다는 것이 보장되므로 이것을 클린 리더 선출이라 합니다.

하지만 동기화된 레플리카들이 아예 없다면 어떻게 해야하는지 두 가지 시나리오로 알아보겠습니다.

> Scenario 1

파티션에는 3 개의 레플리카가 있는데 2 개의 팔로어를 사용할 수 없게 되었습니다. 프로듀서가 리더에 계속 쓰는 동안 모든 메세지는 수신이 확인되고 커밋됩니다. 사용할 수 있는 동기화된 레플리카가 리더뿐이기 떄문입니다.

다음에는 리더를 사용할 수 없게 된다고 가정해보겠습니다. 비동기화 팔로어 중 하나가 먼저 시작된다면, 결국 해당 파티션의 사용할 수 있지만 유일한 레플리카로 비동기화 팔로어만 남게됩니다.

> Scenario 2

파티션에 3 개의 레플리카가 있습니다. 네트워크에 문제가 생겨 2 개의 팔로어가 복제가 뒤쳐졌습니다. 그리고 여전이 사용할 수는 있지만 동기화되지 않게 되었습니다.

이 경우 리더는 유일한 동기화 레플리카가 되어 메세지를 계속 받습니다. 그 다음에 리더를 사용할 수 없게 된다면, 두 개의 사용 가능한 레플리카들은 이후로도 계속 동기화될 수 없습니다.

두 개의 시나리오에서 다음과 같은 판단을 내립니다.

* 비동기화 레플리카를 새로운 리더가 될 수 없게 한다면, 해당 파티션은 이전 리더가 온라인이 될 때까지 오프라인 상태로 남게 된다. 상황에 따라서는 수 시간이 걸릴 수 있다.
* 비동기화 레플리카를 새로운 리거다 될수 있게 한다면, 해당 레플리카가 동기화 되지 않는 동안 이전 리더에 썻던 메세지들을 잃게 되고 컨슈머 간에 일관성도 결여될 수 있다.

비동기화 레플리카가 리더가 될 수 있게 한다면 데이터 유실과 일관성 결여의 위험을 감수해야 하며, 그렇지 않고 리더가 될 수 없게 한다면, 가용성이 떨어지는 것에 직면하게 됩니다. 원래 리더를 사용할 수 있게 되어 해당 파티션이 다시 온라인 상태로 될 때까지 기다려야합니다.

`unclean.leader.election.enable` 를 false 로 설정하면 리더가 온라인이 되기를 기다린다는 의미이므로 가용성이 떨어 질 수 있습니다. 일반적으로 데이터 품질과 일관성이 중요한 시스템에서는 언클린 리더 선출을 하지 못하게됩니다.

### Minimum In-Sync Replicas 

토픽과 브로커 구성에 관련된 구성 매개변수로 `min.insync.replicas` 가 있습니다.

이미 알아봤듯이 하나의 토픽이 3 개의 레플리카를 갖도록 구성되었더라도 동기화 레플리카는 하나만 남게 될 수 있습니다. 그리고 이 레플리카마저 사용할 수 없게 된다면 가용성과 일관성 중 어느 쪽에 비중을 둘 지 선택해야 합니다. Kafka 의 신뢰성 보장에서는 모든 동기화 레플리카에 메세지를 썼을 때 커밋된 것으로 간주하지만(acks=all) 하나만 남은 동기화 레플리카마저 사용할 수 없게 되면 데이터가 유실될 수 있다는 문제가 있기 때문입니다.

커밋된 데이터를 하나 이상의 레플리카에 확실하게 쓰고자 한다면, 동기화 레플리카의 최소 개수를 더 큰 값으로 설정해야 합니다. 하나의 토픽이 3 개의 레플리카를 가질 떄 `min.insync.replicas` 매개변수를 2 로 설정하면 3 개의 레플리카 중에서 최소 2 개가 동기화될 때 토픽의 파티션에 쓸 수 있습니다.

이 경우 3 개의 모든 레플리카가 동기화된다면 모든 것이 정상으로 처리됩니다. 만약 3개 중 2개를 사용할 수 없게 되면 브로커들이 더 이상 쓰기 요청을 받지 않게 되며, 데이터를 쓰려고 하는 프로듀서는 `NotEnoughReplicasException` 에러를 받게 됩니다.

그러나 컨슈머는 기존 데이터를 계속 읽을 수 있습니다. 이 경우 하나의 동기화 레플리카가 읽기 전용이 되는 셈이며, 그럼으로써 바람직하지 않은 데이터를 읽고 쓰는것을 방지하고 언클린 리더가 선출되지 않게 합니다. 

그리고 읽기 전용 상황을 원래대로 복구하기 위해서는 사용 불가능한 2 개의 레플리카 중 하나를 다시 사용할 수 잇게 한 후 밀렸던 메세지를 처리하고 동기화되도록 해야 합니다.

## Using Producers in a Reliable System 

브로커를 신뢰성있게 구성하더라도 프로듀서 역시 신뢰성 있게 구성하지 않는다면 시스템 전체로는 데이터가 유실될 수 있습니다.

이것을 보여주는 2 가지 시나리오가 있습니다. 

두 가지 시나리오 모두 3 개의 레플리카를 가지는 브로커들을 언클린 리더 선출을 할 수 없게 구성하였습니다. 따라서 Kafka 클러스터에 커밋된 메세지는 하나도 유실되지 않습니다.

> Scenario 1

하지만, 프로듀서의 acks 매개변수는 1 로 설정하였습니다. 그러므로 프로듀서가 메세지를 전송하면 리더에 쓰게 되지만 동기화 레플리카에는 아직 쓰지 않은 상태입니다. 그리고 리더는 프로듀서에게 *Message was written successfully* 라 응답한 후 데이터가 다른 레플리카에 복제되기 전에 곧바로 중단되었습니다. 이 경우 다른 레플리카들은 여전히 동기화 중인 것으로 간주하여 그중 하나가 리더가 됩니다. 이때 해당 메세지는 새로 리더가 된 레플리카에 쓰지 않았으므로 유실될 것입니다.

그러나 프로듀서 어플리케이션에서는 해당 메세지를 성공적으로 썻다고 간주합니다. 또한 컨슈머도 해당 메세지를 읽지 않았으므로 일관성은 유지됩니다. 하지만 프로듀서 관점에서는 메세지가 유실된 것입니다.

> Scenario 2

Kafka 에 메세지를 쓰려고 하는데, 해당 파티션의 리더가 중단되어 새로운 리더가 선출되는 중이라 가정해보겠습니다. 이때 Kafka 는 *Leader not Available* 이라는 응답을 합니다. 이 시점에서 쓰기가 성공적으로 될 때까지 프로듀서가 해당 에러를 제대로 처리하지 못하여 재시도하지 않는다면 메세지가 유실될 수 있습니다. 

다시 말하자면 브로커의 신뢰성 문제가 아닙니다. 또한 컨슈머도 메세지를 읽지 않았으므로 일관성 문제 역시 아닙니다. 하지만 프로듀서가 에러를 제대로 처리하지 못한다면 메세지 유실을 초래할 수 있습니다.

---

메세지를 쓰는 모든 프로듀서는 다음 두 가지에 주의해야 합니다.

* 신뢰성 요구 사항에 맞도록 acks 구성 매개변수를 올바르게 설정해야 합니다.
* 구성 매개변수와 코드 모두에서 에러 처리를 올바르게 해야한다.

### Send Acknowledgments 

프로듀서는 다음 세 가지 확인 응답 모드 중 하나를 acks 구성 매개변수에 설정할 수 있습니다.

* acks=0
  * 프로듀서가 네트워크로 메세지를 전송했다면 Kafka 가 성공적으로 쓴 것으로 간주합니다. 이 경우 전송하는 객체가 직렬화될 수 없거나 네트워크 카드에 장애가 생기면 프로듀서가 에러를 받습니다. 하지만, 메세지를 쓸 파티션이 오프라인이거나 관련 Kafka 클러스터의 처리가 늦어지는 경우에는 에러를 받지 않습니다.
  * acks=0 인 경우 실행속도는 매우 빠르므로 놀라운 처리량을 얻을 수 있습니다. 하지만 일부 메세지가 유실될 수 있습니다.
* acks=1
  * 리더가 메세지를 수신하고 파티션 데이터 파일에 쓴 후 확인 응답 또는 에러를 전송합니다. 따라서 정상적인 리더 선출 상황에서 리더가 선출 중일 경우 프로듀서는 `LeaderNotAvailableException` 에러를 받습니다.
  * 리더가 성공적으로 쓰고 확인 응답한 일부 메세지가 리더 중단 시점에 팔로워에 복제되지 않았다면 유실될 수 있습니다.
* acks=all
  * 확인 응답이나 에러 전송에 앞서, 모든 동기화 레플리카가 메세지를 받을때까지 기다립니다.
  * 모든 레플리카가 메세지를 받을동안 프로듀서가 기다려야 하므로 처리속도가 가장 느립니다.
  
### Configuring Producer Retries 

프로듀서의 에러 처리에는 두 가지가 있습니다. 자동으로 처리하는 에러와 개발자가 라이브러리를 사용해서 처리하는 에러입니다.

프로듀서는 브로커가 반환하는 **재시도 가능한(Retriable)** 에러를 처리할 수 있습니다. 보통 두 가지 부류가 있습니다. 전송을 재시도했을 시 해결되는 에러와 해결이 안 되는 에러입니다.

예를 들어 브로커가 `LEADER_NOT_AVAILABLE` 에러 코드를 반환하면 프로듀서는 메세지 전송을 다시 시도할 수 있습니다. 즉 새로운 브로커가 리더로 선출되었을 것이므로 두 번째 시도는 성공할 것입니다. 즉, `LEADER_NOT_AVAILABLE` 은 재시도 가능한 에러입니다.

반대로 `INVALID_CONFIG` 예외를 반환하면 같은 메세지를 다시 전송해도 구성이 변경되지 않습니다. 이것은 재시도 불가능한 에러입니다.

### Additional Error Handling 

Kafka 프로듀서 객체가 자동으로 해주는 재시도를 사용하면 메세지 유실 없이 다양한 에러를 올바르고 쉽게 처리해줍니다. 하지만 개발자가 처리해야 하는 에러도 있습니다.

* 메세지 크기, 인증 에러 등과 같이 재시도 불가능한 브로커 에러
* 메세지가 브로커에게 전송되기 전에 발생한 에러, 예를 들어 직렬화 에러
* 구성 매개변수에 지정된 횟수만큼 프로듀서가 재시도했을 때 또는 전송을 재시도하는 동안 메세지들을 저장하는 것 때문에 프로듀서가 사용할 수 있는 메모리가 꽉 찼을 때 발생하는 에러

만약 에러 처리 코드에서 메세지 재전송을 시도하는 것이 전부라면 Kafka 프로듀서 객체가 자동으로 해주는 재전송 시도를 사용하는 것이 좋습니다.

## Using Consumers in a Reliable System 

데이터는 Kafka 에 커밋된 후에만 컨슈머가 읽을 수 있습니다. 따라서 컨슈머는 일관성이 보장된 데이터를 읽습니다. 그리고 컨슈머는 읽은 메세지와 읽지 않은 메세지를 계속 파악하면 됩니다. 이것이 메세지를 읽는 동안 누락시키지 않는 방법입니다.

파티션의 데이터를 읽을 때 컨슈머는 메세지 배치를 읽고 처리한 후 해당 배치의 마지막 오프셋을 확인하여 그 오프셋부터 시작하는 다른 메세지 배치의 읽기를 요청합니다. 따라서 메세지의 눌가 없이 Kafka 컨슈머가 항상 올바른 순서로 데이터를 읽게 해줍니다.

특정 컨슈머가 중단되면 어디서부터 계속 읽어야 할지 다른 컨슈머가 알아야 합니다. 즉, 이전 컨슈머가 중단되기 전에 읽고 처리했던 파티션의 마지막 오프셋을 알아야 한다는 의미입니다. 컨슈머가 자신의 오프셋을 **커밋** 해야 하는 이유가 바로 그 때문입니다.

주로 컨슈머는 다음의 경우에 메세지를 누락시킬 수 있습니다. 즉, 이미 읽었지만 아직 완전히 처리되지 않은 메세지의 오프셋을 커밋할 때입니다. 이 경우 다른 컨슈머가 이어서 읽을 때 메세지들은 읽지 않게 되고 처리도 되지 않습니다. 언제 어떻게 오프셋을 커밋하느냐가 중요한 이유가 바로 이 때문입니다.

### Important Consumer Configuration Properties for Reliable Processing 

신뢰성 있는 컨슈머를 구성하기 위해 알아두어야 할 컨슈머 구성 속성에는 4 개가 있습니다.

첫 번째는 `group.id` 입니다. 

2 개의 컨슈머가 같은 그룹 ID 를 갖고 같은 토픽을 구독하면, 각 컨슈머는 해당 토픽의 일부 파티션을 분담하므로 할당받은 파티션의 메세지만 읽게 됩니다. 만약 구독하는 토픽의 모든 메세지를 하나의 컨슈머가 읽는다면 별도의 고유한 그룹 ID 를 `group.id` 에 설정하고 사용하면 됩니다.

두 번쨰는 `auto.offset.reset` 입니다.

커밋된 오프셋이 없거나 브로커에 없는 오프셋을 컨슈머가 요청할 때 컨슈머가 할 일을 제어하는 것이 이 매개변수입니다. 설정 값에는 두 가지가이 있습니다. `earlist` 를 설정하면 컨슈머가 해당 파티션의 맨 앞부터 모든 데이터를 읽습니다.

`latest` 를 설정하면 컨슈머는 해당 파티션의 제일 끝부터 읽기 시작합니다. 이것은 중복해서 읽는 것을 최소화하지만 컨슈머가 일부 메세지들을 누락시킬 가능성이 있습니다.

세 번째는 `enable.auto.commit` 입니다.

이 매개변수는 컨슈머의 오프셋 커밋을 자동으로 할건지 코드에서 직접 할 것인지를 결정합니다.

만약 읽은 메세지의 모든 처리를 컨슈머의 폴링 루프 안에서 한다면, 처리한 메세지의 오프셋만 커밋되도록 자동 오프셋 커밋이 보장해줍니다. 단, 중복되는 메세지 처리를 제어할 수 없다는 것이 자동 오프셋 커밋의 단점입니다.

마지막으로 `auto.commit.interval.ms` 가 있으며 `enable.auto.commit` 과 연관지어 설정합니다. `enable.auto.commit` 의 값을 `true` 일 때 `auto.commit.interval.ms` 를 설저앟여 자동으로 오프셋을 커밋하는 시간 간격을 제어할 수 있습니다.

### Explicitly Committing Offsets in Consumers 

자동 오프셋 커밋을 사용한다면 오프셋 커밋을 신경 쓰지 않아도 됩니다. 하지만 오프셋을 커밋하는 시점 외에 다른 것도 제어해야 한다면 어떻게 할 것인지 신중하게 생각해야 합니다.

#### Always commit offsets after events were processed

컨슈머의 폴링 루프 안에서 모든 처리를 하고 폴링 루프가 반복될 때마다 상태 정보를 유지하지 않는다면, 자동 오프셋 커밋을 사용하도록 구성하거나 폴링 루프의 끝에서 커밋하면 됩니다.

#### Commit frequency is a trade-off between performance and number of duplicates in the event of a crash

컨슈머의 폴링 루프 안에서 모든 처리를 하고 폴링 루프가 반복될 때마다 상태 데이터를 유지하지 않는 가장 간단한 경우일지라도, 폴링 루프 내부에서 여러 번 커밋하거나 몇 차례 반복할 때만 커밋할 수 있습니다. 

오프셋 커밋은 성능에 부담을 약간 줍니다.

#### Make sure you know exactly what offsets you are committing

컨슈머의 폴링 루프 중간에서 커밋할 때는 처리된 마지막 오프셋이 아닌 읽기만 한 마지막 오프셋을 커밋하는 오류를 범할 수 있습니다. 항상 처리된 메세지의 오프셋을 커밋하는 것이 중요하다는 것을 생각해야합니다.

#### Rebalances

메세지의 중복 처리를 방지하기 위해서 컨슈머 리밸런싱이 시작되기 전에 마지막 처리된 메세지의 오프셋을 커밋하는 등의 클린업 처리를 해야 합니다.

#### Consumers may need to retry

어플리케이션에 따라서 `poll()` 메서드 호출 간에 상태 데이터를 유지해야 할 경우가 있습니다.

오프셋을 커밋하는 동시에 가장 최근의 상태를 특정 토픽에 쓰는것이 한 가지 방법입니다. 이렇게 하면 컨슈머 스레드가 시작될 때 마지막 상태를 찾을 수 있습니다. 하지만, 마지막 상태 값을 쓰고 오프셋을 커밋하기전에 컨슈머가 중단되는 문제가 발생할 수 있습니다.

#### Handling long processing times

레코드를 스레드풀에 전달하면 병행 처리로 다수의 스레드를 사용할 수 있기 때문에 처리속도를 높일 수 있습니다. 그리고 컨슈머에서는 스레드풀의 작업 스레드들에게 레코드들을 전달한 후 레코드 처리는 하지 않고 폴링만 계속하면서 작업 스레드들이 완료될 때까지 기다리면 됩니다. 그 다음 작업 스레드들이 완료된 후 데이터 읽기를 수행하면 됩니다.

#### Exactly-once delivery

일부 어플리케이션에서는 `at-least-once` 전송은 물론이고 `exactly-once` 전송도 필요합니다. `exactly-once` 는 프로듀서가 메세지를 전송하며 브로커가 수신하고 복제까지 완료한 후 커밋 확인 응답을 프로듀서에게 전송하는 것이 정상적인 메세지 쓰기 경로이며, 전송 과정 중에 문제가 생기지 않으면 메세지가 유실되지 않고 정확히 한 번만 쓰게하는것입니다.

`exactly-once` 전송을 하기 위해 가장 많이 사용되는 방법은 고유한 키를 지원하는 외부 시스템에 식별 데이터를 쓰는 것입니다. 이때 Key-Value 데이터 스토어, RDB, ELK 등의 시스템을 사용할 수 있습니다. 외부 시스템에 데이터를 쓸 때 Kafka 레코드 자체에 고유한 키를 포함하거나, 토픽과 파티션 및 오프셋을 조합하여 고유한 키를 생성하면 됩니다.

이외에도 트랜잭션 처리가 가능한 외부 시스템에 쓰는 바업ㅂ이 있습니다. 이런 외부 시스템의 가장 쉬운 예는 RDB 이며, HDFS 도 흔히 사용됩니다. 이 방법에서는 같은 트랜잭션에 Kafka 레코드와 오프셋을 써서 동기화되도록 합니다.

## Validating System Reliability 

### Validating Configuration 

Kafka 는 구성 검사에 도움이 되는 두 개의 도구를 포함하고 있습니다. `org.apache.kafka.tools` 패키지에 있는 `VerifiableProducer` 와 `VerifiableConsumer` 클래스입니다.

**검사 가능한 프로듀서(VerifiableProducer)** 는 1 부터 선택한 값까지의 숫자를 포함하는 메세지를 Kakfa 에 씁니다. 이때 `acks.retries` 구성 매개변수의 적합한 값을 설정하여 그 프로듀서를 구성할 수 있습니다. 그리고 실행하면 `acks` 에 근거하여 브로커에 전송된 각 메세지의 성공 또는 에러를 출력합니다.

**검사 가능한 컨슈머(VerifiableConsumer)** 는 상호 보완적인 검사를 수행합니다. 즉, 메세지를 읽은 후 순서대로 출력합니다. 또한 커밋과 리밸런싱에 관련된 정보도 출력합니다.

어떤 테스트를 할 것인지도 고려해야합니다. 테스트 시나리오의 예를 들면 다음과 같습니다.

* Leader election: what happens if I kill the leader? How long does it take the producer and consumer to start working as usual again?
* Controller election: how long does it take the system to resume after a restart of the controller?
* Rolling restart: can I restart the brokers one by one without losing any messages?
* Unclean leader election test: what happens when we kill all the replicas for a partition one by one (to make sure each goes out of sync) and then start a broker that was out of sync? What needs to happen in order to resume operations? Is this acceptable?

그 다음 하나의 시나리오를 골라서 검사 가능한 프로듀서와 검사 가능한 컨슈머를 시작시킵니다. 그리고 해당 시나리오에 있는 대로 실행합니다.

### Validating Applications 

브로커와 클라이언트의 구성이 요구사항을 충족시키는지 확인한 다음에는 어플리케이션에서 필요한 신뢰성을 보장하는지 테스트합니다.

어플리케이션을 검사할 때는 다양한 장애 상황에서 실행 테스트를 할 것을 권합니다. 테스트 시나리오의 예는 다음과 같습니다.

* Clients lose connectivity to the server (your system administrator can assist you in simulating network failures)
* Leader election
* Rolling restart of brokers
* Rolling restart of consumers
* Rolling restart of producers

### Monitoring Reliability in Production 

어플리케이션을 테스트하는것도 중요합니다. 하지만 데이터가 예상대로 이동하는지 확인하기 위해 실제 업무 시스템을 지속적으로 모니터링하는 것을 대체할 수는 없습니다. 그래서 클러스터의 모니터링 뿐만 아니라 시스템을 통한 클라이언트와 데이터의 이동을 모니터링하는 것도 중요합니다.