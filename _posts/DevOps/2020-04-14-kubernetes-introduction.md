---
title : Introducing Kubernetes
tags :
- Docker
- Kubernetes
---

*이 포스트는 [Kubernetes In Action](https://github.com/KeKe-Li/book/blob/master/kubernetes/Kubernetes%20in%20Action.pdf)를 바탕으로 작성하였습니다.*

이전의 소프트웨어 어플리케이션은 하나의 프로세스나 몇 개의 서버에 분산된 프로세스로 실행되는 거대한 **모놀리스(Monolith)** 였습니다. 이런 레거시 시스템은 지금도 존재하며, 릴리스 주기가 느리고 업데이트가 자주되지않습니다.

개발자는 릴리스 주기가 끝날 때마다 전체 시스템을 패키징하고 운영 팀에게 넘기면 운영 팀은 이를 배포하고 넘깁니다. 운영 팀은 하드웨어 장애가 발생하면 이를 사용 가능한 서버로 직접 마이그레이션 합니다.

이런 거대한 시스템은 점차 마이크로서비스라는 독립적으로 실행되는 작은 구성 요소로 세분화됩니다. 마이크로 서비스는 서로 분리되어있기 때문에 개별적으로 배포, 업데이트, 확장할 수 있습니다. 이로써 오늘날 급변하는 비즈니스 요구 사항을 충족시킬만큼 신속하게 자주 구성요소를 변경할 수 있습니다.

배포 가능한 구성 요소가 많아지고 데이터 센터 규모가 커지면서 전체 시스템을 구성, 관리, 유지하는 일이 어려워졌습니다. 이런 구성 요소의 서버 배포를 자동으로 스케줄링하고, 구성, 관리, 장애 처리를 자동화하는 것이 Kubernetes 입니다.

Kubernetes 는 개발자가 운영 팀의 도웁 없이도 자신의 어플리케이션을 원하는 만큼 자주 배포할 수 있도록 합니다.

Kubernetes 는 하드웨어 인프라를 추상화하고 데이터 센터 전체를 하나의 거대한 컴퓨팅 리소스로 제공합니다. 실제 세세한 서버 정보를 알 필요 없이 어플리케이션 구성 요소를 배포하고 실행할 수 있습니다. Kubernetes 로 여러 어플리케이션 구성 요소를 배포할 때 각 구성 요소 서버를 선택하고 배포하며 어플리케이션의 다른 구성 요소를 쉽게 찾고 통신할 수 있습니다.

Kubernetes 는 대규모 데이터 센터에서 사용할 때 진가를 발휘합니다. Kubernetes 는 개발자가 모든 유형의 어플리케이션을 배포하고 실행할 수 있는 간단한 플랫폼을 제공하고 클라우드 공급자의 시스템 관리자가 하드웨어에서 작동하는 많은 어플리케이션을 일일이 알 필요를 없게합니다.

## Understanding the Need for a System Like Kubernets

Kubernetes 로 인해 변화된 어플리케이션의 개발 배포 방식을 알아보겠습니다.

### Moving from monolithic apps to microservices

모놀리스 어플리케이션은 서로 강하게 결합돼있고 전체가 하나의 운영체제 프로세스로 실행되므로 하나의 개체로 개발 배포 관리해야합니다. 어플리케이션의 한 부분을 변경하더라도 전체 어플리케이션을 재배포해야합니다. 이로 인해 전체 시스템의 복잡성이 증가하고 품질이 저하됩니다.

모놀리스 어플리케이션을 실행하려면 충분한 리소스를 제공할 수 있는 소수의 강력한 서버가 필요하합니다. 시스템의 증가하는 부하를 처리하기 위해 구성 요소를 추가해 서버를 **수직 확장(Scale Up)** 하거나 서버를 추가하여 전체 시스템을 **수평 확장(Scale Out)** 해야 합니다.

수직 확장은 어플리케이션을 변경할 필요가 없지만 비용이 많이들고 확장에 한계가 있습니다. 하지만 모놀리스 어플리케이션의 일부분이 수평적으로 확장하기 매우 어렵거나 불가능하여 어플리케이션 확장이 불가능합니다.

#### Splitting apps into microservices

이런 문제를 해결하기 위해 복잡한 모놀리스 어플리케이션을 마이크로서비스라는 독립적으로 배포할 수 있는 작은 구성 요소로 분할해야 합니다. 각 마이크로서비스는 독립적인 프로세스로 실행되며 단순하고 잘 정의된 또 다른 마이크로서비스와 통신합니다.

> Example 1 - Components inside a monolithic application vs. standalone microservices

![image](https://user-images.githubusercontent.com/44635266/78467391-545d3780-7747-11ea-98cb-d5fc048e9250.png)

마이크로서비스는 일반적으로 RESTful API 를 제공하는 HTTP 와 같은 동기 프로토콜과 AMQP 같은 비동기 프로토콜로 통신합니다. 이 프로토콜은 단순하고 특정 개발 언어에 종속적이지 않습니다. 각 마이크로서비스는 해당 마이크로서비스를 구현하는데 가장 적합한 언어로 만들 수 있습니다.

각 마이크로서비스는 대체로 정적인 외부 API 를 제공하거나 독립형 프로세스이기 때문에 개별적으로 개발, 배포할 수 있습니다. API 가 변경되지 않거나 이전 버전과 호환되는 방식으로 변경됐다면 이들 중 하나를 변경해도 다른 서비스를 변경하거나 재배포하지 않아도 됩니다.

#### Scaling microservices

전체 시스템을 같이 확장해야하는 모놀리스 시스템과 달리 마이크로서비스 확장은 서비스별로 수행되므로 리소스가 더 필요한 서비스만 별도로 확장할 수 있으며 다른 서비스는 그대로 됩니다. `Example 2` 는 그 예를 보여줍니다.

특정 요소는 서로 다른 서버에 배포된 여러 프로세스로 복제, 실행되며 다른 구성 요소는 어플리케이션 프로세스 하나로 실행됩니다. 모놀리스 어플리케이션의 구성 요소가 확장 불가능한 경우 어플리케이션을 마이크로서비스 형태로 분할해 수평 확장을 가능하게 하거나 수평 확장이 불가능한 경우 수직 확장할 수 있습니다.

> Example 2 - Each microservice can be scaled individually.

![image](https://user-images.githubusercontent.com/44635266/78467431-bcac1900-7747-11ea-9809-a156b32e4115.png)

#### Deploying microservices

마이크로서비스는 시스템이 소수의 구성 요소로만 구성되어 쉽게 관리할 수 있습니다. 하지만 구성 요소가 많아지면 배포 조합의 수뿐만 아니라 구성 요소 간의 상호 종속성 수가 많아지므로 배포 관련 결정이 점점 어려워집니다.

마이크로 서비스는 여러 개가 서로 함께 작업을 수행하므로 서로를 찾아 통신해야합니다. 배포할 때 전체가 하나의 시스템처럼 동작할 수 있도록 제대로 구성해야합니다.

또한 마이크로서비스는 여러 프로세스와 시스템에 분산돼 있기 때문에 실행 호출을 디버깅하고 추적하기 어렵습니다. 이런 문제는 현재 Zipkin 같은 분산 추적 시스템으로 해결합니다.

#### Understanding the divergence of environment requirements

마이크로서비스 아키텍처의 구성 요소는 독립적으로 배포될 뿐만 아니라 독립적인 방식으로 개발됩니다. 마이크로 서비스의 독립성과 각 구성 요소를 개발하는 별도의 팀이 있는 것이 일반적이기 때문에 각 팀이 라이브러리를 사용하고 필요할 때마다 교체하는 것을 방해해서는 안됩니다. `Example 3` 에 나타난것처럼 어플리케이션이 서로 다른 버전의 동일한 라이브러리를 필요로 하는 경우 종속성 차이는 불가피합니다.

> Example 3 - Multiple applications running on the same host may have conflicting dependencies.

![image](https://user-images.githubusercontent.com/44635266/78467438-c7ff4480-7747-11ea-9e10-49a813231676.png)

### Providing a consistent environment to applications

프로덕션 시스템은 여러 개발자나 개발 팀의 어플리케이션을 실행할 수 있으나 개발자의 컴퓨터는 그렇지 않습니다. 프로덕션 시스템은 상충되는 서로 다른 버전의 라이브러리를 필요로 할지라도 운영하는 모든 어플리케이션에 적절한 환경을 제공해야합니다.

운영체제, 라이브러리, 시스템 구성, 네트워킹 환경, 기타 모든 것이 동일한 환경을 만들 수 있다면 이상적일 것입니다.

### Moving to continuous delivery: DevOps and NoOps

과거 개발팀의 업무는 어플리케이션을 만들고 이를 배포하고 관리하며 계속 운영하는 운영 팀에 넘겨주는것입니다. 하지만 이제는 개발 팀이 어플리케이션을 배포하고 관리합니다. 즉 개발자, QA, 운영 팀이 전체 프로세스에서 협업한다는 의미입니다.

이런 작업 방식을 **데브옵스(DevOps)** 라고 부릅니다.

#### Understanding the benefits

개발자가 프로덕션 환경에서 어플리케이션을 실행하는 데 더많이 관여하게 되면, 사용자가 무엇을 필요로 하고 어떤 문제가 있는지, 더 잘 이해할 수 있습니다. 어플리케이션 개발자는 이제 어플리케이션을 신속하게 제공할 수 있으므로 사용자의 피드백을 추가적인 개발에 반영할 수 있습니다.

#### Letting developers and sysadmins do what they do best

Kubernets 를 사용하면 하드웨어를 추상화하고 이를 어플리케이션 배포, 실행을 위한 플랫폼을 제공하여 개발자는 시스템 관리자의 도움 없이도 어플리케이션을 구성, 배포할 수 있으며 시스템 관리자는 실제 실행되는 어플리케이션을 알 필요 없이 인프라를 유지하고 운영하는 데 집중할 수 있습니다.

## Introducing Container Technologies

Kubernets 는 어플리케이션을 격리하는 기능을 제공하기 위해 리눅스 컨테이너 기술을 사용하므로, 컨테이너의 기본에 익숙해져야 합니다. 또한 Docker 나 rkt 과 같은 컨테이너 기술이 어떤 문제를 해결하는지 이해해야 합니다.

### Understanding what containers are

어플리케이션이 작은 수의 구성요소로 이뤄진 경우 구성 요소에 가상머신을 제공하고 고유한 운영체제 인스턴스를 제공하여 환경을 격리시킬 수 있습니다.

하지만 구성요소가 작아지고 많아질수록 각 구성요소마다 가상머신을 제공할 수 없습니다. 이는 하드웨어 리소스 낭비만이 아니라 가상머신을 개별적으로 관리하는 시스템 관리자의 작업량이 증가하기 때문에 가상머신은 인적 자원도 낭비됩니다.

#### Isolating components with Linux container technologies

가상머신을 사용해 각 마이크로서비스의 환경을 격리하는 대신 개발자들은 리눅스 컨테이너 기술로 눈을 돌렸습니다. 동일한 호스트 시스템에서 여러개의 서비스를 실행할 수 있으며 동시에 서로 다른 환경을 만들어줄 뿐만 아니라 가상머신과 유사하게 서로 격리하지만 오버헤드가 훨씬 적습니다.

컨테이너에 실행되는 프로세스는 다른 모든 프로세스와 마찬가지로 호스트 운영체제 내에서 실행됩니다. 하지만 컨테이너의 프로세스는 여전히 다른 프로세스와 격리돼 있습니다. 프로세스 입장에서 보면 시스템과 운영체제에 실행되는 유일한 프로세스처럼 보입니다.

#### Comparing virtual machines to containers

컨테이너를 가상머신과 비교하면 컨테이너는 훨씬 더 가벼워 동일한 하드웨어에서 더 많은 수의 소프트웨어 구성 요소를 실행할 수 있습니다. 가상 머신은 구성 요소 프로세스뿐만 아니라 시스템 프로세스를 실행해야 하기 때문에 추가 컴퓨팅 리소스가 필요합니다.

반면 컨테이너는 호스트 OS 에서 실행되는 하나의 격리된 프로세스에 지나지 않으며, 어플리케이션이 소비하는 리소스만 소비하고 추가 프로세스의 오버헤드는 없습니다.

가상머신의 오버헤드로 인해 각 어플리케이션별로 하나의 VM 을 전용으로 사용하기에는 리소스가 충분하지 않기 때문에 각 가상머신에 여러 어플리케이션을 그룹으로 배포하는 경우가 있습니다.

컨테이너를 사용하면 `Example 4` 와 같이 어플리케이션마다 하나의 컨테이너를 가질 수 있습니다. 그 결과 동일한 베어메탈 머신에서 더 많은 어플리케이션을 적재할 수 있습니다.

> Example 4 - Using VMs to isolate groups of applications vs. isolating individual apps with containers

![image](https://user-images.githubusercontent.com/44635266/78467538-cd10c380-7748-11ea-9b7f-2bffad9cb7f2.png)

호스트에 가상머신 3 개를 실행하면 3 개의 완전히 분리된 운영체제가 실행되고 동일한 베어메탈 하드웨어를 공유합니다. 이런 가상머신 아래에는 물리적 하드웨어 리소스를 각 가상머신 내부의 운영체제에서 사용할 수 있는 더 작은 리소스로 나누는 호스트 OS 와 하이퍼바이저가 있습니다.

해당 가상머신 내에서 실행되는 어플리케이션이 가상머신의 게스트 OS 커널에 시스템 콜을 수행하면, 커널은 하이퍼바이저로 호스트의 물리적 CPU 에 x86 명령어를 수행합니다.

반면 컨테이너 호스트 OS 에 실행되는 동일한 커널에서 시스템 콜을 수행합니다. 이 커널은 호스트의 CPU 에 x86 명령을 수행하는 유일한 커널입니다. CPU 는 가상머신과 같은 방식으로 어떠한 종류의 가상화도 필요 없습니다.(`Example 5`)

가상머신의 주요 이점은 각 가상머신이 자체 리눅스 커널을 실행해 완전 격리를 제공하는 데 반해 컨테이너는 모두 동일한 커널을 호출하여 보안 위험이 발생할 수 있다는 것입니다.

하드웨어 리소스가 제한되는 경우 격리하려는 프로세스가 적은 경우에만 가상머신을 사용할 수 있습니다. 동일한 시스템에 더 많은 수의 격리된 프로세스를 실행하려면 컨테이너의 오버헤드가 낮기 때문에 컨테이너를 선택하는것이 좋습니다.

각 가상머신은 자체 시스템 서비스를 실행하지만 컨테이너는 모두 동일한 OS 에서 실행되므로 컨테이너는 시스템 서비스를 실행하지 않습니다. 

즉, 컨테이너는 가상머신처럼 부팅할 필요가 없습니다. 컨테이너에서 실행되는 프로세스는 즉시 시작됩니다.

> Example 5 - The difference between how apps in VMs use the CPU vs. how they use them in containers

![image](https://user-images.githubusercontent.com/44635266/78467541-d7cb5880-7748-11ea-8264-aec4d4bd6733.png)

#### Introducing the mechanisms that make container isolation possible

컨테이너가 동일한 운영체제에서 실행 중인 경우 두 가지 메커니즘으로 프로세스를 격리시킵니다.

첫 번재는 리눅스 네임스페이스로 각 프로세스가 시스템에 대한 독립된 뷰만 볼 수 있도록 합니다.

두 번재는 리눅스 컨트롤 그룹으로, 프로세스가 사용할 수 있는 리소스 양을 제한합니다.

#### Isolating processes with Linux Namespaces

리눅스 시스템은 초기 구동시 하나의 네임스페이스가 있습니다. 파일 시스템, 프로세스 ID, 사용자 ID, 네트워키 언테피으스 등 모든 시스템 리소스는 하나의 네임스페이스에 속합니다.

추가 네임스페이스를 생성하고 리소스를 구성할 수 있습니다. 프로세스를 실행할 때 해당 네임스페이스 중 하나에서 프로세스를 싱행합니다. 프로세스는 동일한 네임스페이스 내에 있는 리소스만 볼 수 있습니다.

여러 종류의 네임스페이스가 있기 때문에 프로세스는 하나의 네임프로세스에만 속하는 것이 아니랑 ㅕ러 네임스페이스에 속할 수 있습니다.

네임 스페이스의 종류는 다음과 같습니다.

* Mount (mnt)
* Process ID (pid)
* Network (net)
* Inter-process communication (ipc)
* UTS
* User ID (user)

각 네임스페이스는 특정 리소스 그룹을 격리할 때 사용합니다. 예를 들어 UTS 를 각각 지정하면 서로 다른 로컬 호스트 이름을 보여주며, 프로세스를 마치 두 개의 다른 시스템에서 실행중인 것처럼 보이게 할 수 있습니다.

프로세스가 속한 네트워크 네임스페이스는 실행 중인 어플리케이션의 프로세스에서 볼 수 있는 네트워크 인터페이스를 결정합니다. 각 네트워크 인터페이스는 정확히 하나의 네임스페이스에 속하지만 다른 네임스페이스로 이동할 수 있습니다.

각 컨테이너는 고유한 네트워크 네임스페이스를 사용하므로 각 컨테이너는 고유한 네트워크 인터페이스 세트를 볼 수 있습니다.

네임스페이스를 사용해 컨테이너에서 실행하는 어플리케이션을 분리하는 방법을 알 수 있습니다.

#### Limiting resources available to a process

격리의 나머지 부분은 컨테이너가 사용할 수 있는 리소스 양을 제한합니다. 이는 프로세스의 리소스 사용르 제한하는 커널 기능인 `cgroups` 로 이루어집니다.

프로세스는 설정된 양 이상의 CPU, 메모리, 네트워크 대역폭등을 사용할 수 없습니다.

### Introducing the Docker container platform

Docker 기반 컨테이너 이미자와 가상머신 이미지의 가장 큰 차이는 컨테이너 이미지가 여러 이미지에서 공유되고 재사용할 수 있는 레이어로 구성돼 있습니다.

동일한 레이어를 포함하는 경우 다른 컨테이너 이미지를 실행할 때 다른 레이어가 이미 다운로드된 경우 이미지의 특정 레이어만 다운로드하면 됩니다.

#### Understanding Docker concepts

Docker 는 어플리케이션을 패키징, 배포, 실행하기 위한 플랫폼입니다. 어플리케이션을 전체 환경과 함께 패키지화할 수 있습니다. 어플리케이션에 필요한 몇 가지 라이브러리나 운영체제 파일시스템에 설치되는 모든 파일을 포함시킬 수 있습니다.;

Docker 를 사용하면 이 패키지를 중앙 저장소로 전송하며, Docker 를 실행하는 모든 컴퓨터에 전송이 가능합니다.

* Image
  * 어플리케이션과 환경을 패키지화
  * 실행파일 경로와 같은 메타데이터가 포함
* Registry
  * Docker 이미지를 저장하고 다른 사람이나 컴퓨터 간에 해당 이미지를 쉽게 고유할 수 있는 저장소
  * 이미지를 빌드할 대 빌드하는 컴퓨터에서 이미지를 실행하거나 이미지를 레지스트리로 푸시한 다음 다른 컴퓨터에서 풀할 수 있다.
  * 비공개 레지스트리는 특정 사람이나 컴퓨터에만 액세스 가능하다.
* Container
  * Docker 기반 컨테이너 이미지에서 생성된 일반적인 리눅스 컨테이너
  * 호스트에서 실행되는 프로세스지만 호스트와 호스트에 실행 중인 다른 프로세스와 완전히 격리돼 있다.

Docker 의 3 가지 주요 개념은 다음과 같습니다.

#### Building, distributing, and running a Docker image

`Example 6` 은 세 가지 개념과 각각의 관계를 잘 보여줍니다. 개발자는 이미지를 만든 다음 레지스트리로 푸시합니다.

그 다음 도커가 실행되는 다른 컴퓨터로 이미지를 가져와 이미지를 실행할 수 있습니다. 도커는 이미지를 기반으로 격리된 컨테이너를 만들고 이미지의 일부로 지정된 바이너리 실행파일을 실행합니다.

> Example 6 - Docker images, registries, and containers

![image](https://user-images.githubusercontent.com/44635266/78467851-3940f680-774c-11ea-8075-2516d9ebb334.png)

#### Comparing virtual machines and Docker containers

`Example 7` 은 가상머신과 Docker 컨테이너에 실행되는 동일한 어플리케이션 6 개를 보여준다. 차이점을 살펴보겠습니다.

> Example 7 - Running six apps on three VMs vs. running them in Docker containers

![image](https://user-images.githubusercontent.com/44635266/78467855-4231c800-774c-11ea-9b66-2dcceda861f5.png)

가상머신에서 실행될 때와 두 개의 별도 컨테이너로 실행될 때 어플리케이션 A, B 동일한 바이너리, 라이브러리에 접근할 수 있다. 가상 머신에서는 두 어플리케이션이 모두 동일한 파일 시스템에 실행되므로 의심할 여지가 없습니다.

하지만, 각 컨테이너는 격리된 자체 파일 시스템이 있습니다.

#### Understanding image layers

Docker 이미지는 레이어로 구성되어 있습니다. 

모든 Docker 이미지는 다른 이미지 위에 빌드되며 두 개의 다른 이미지는 기본 이미지로 동일한 부모 이미지를 사용할 수 있으므로 다른 이미지에는 정확히 동일한 레이어가 포함될 수 있습니다.

이렇게 하면 첫 번재 이미지의 일부를 전송한 레이어를 다른 이미지를 전송할 때 다시 전송할 필요가 없기 때문에 네트워크로 이미지를 배포하는 속도가 빨라집니다.

레이어는 배포만 효율적이게 할 뿐만 아니라 스토리지 공간을 줄이는데 도움이 됩니다. 각 레이어는 동일 호스트에 한 번만 저장됩니다. 

따라서 동일한 기본 레이어를 기반으로 한 두 개의 이미지에서 생성한 두 개의 컨테이너는 동일한 파일을 읽을 수 있지만 그중 하나가 해당 파일을 덮어쓰면 다른 컨테이너는 해당 변경사항을 볼 수 없습니다.

파일을 공유하더라도 여전히 서로 격리돼 있는데 이것은 컨테이너 이미지 레이어가 읽기 전용이기 때문입니다. 컨테이너가 실행될 때 이미지 레이어 위에 새로운 쓰기 가능한 레이어가 만들어집니다. 컨테이너의 프로세스가 기본 레이어 중 하나에 있는 파일에 쓰면 전체 파일의 복사본의 최상위 레이어에 만들어지고 프로세스는 복사본에 씁니다.

#### Understanding the portability limitations of container images

컨테이너 이미지는 Docker 를 실행하는 모든 리눅스 시스템에서 실행될 수 있지만 호스트에서 실행되는 모든 컨테이너가 호스트의 리눅스 커널을 사용하는 사실과 관련해 주의할 것이 있습니다.

컨테이너화된 어플리케이션이 특정 커널 버전이 필요하다면 모든 시스템에서 작동하지 않을 수 있습니다. 머신이 다른 버전의 리눅스 커널로 실행되거나 동일한 커널 모듈을 사용할 수 없는 경우 어플리케이션이 실행될 수 없습니다.

컨테이너는 가상머신에 비해 가볍지만 컨테이너 내부에 실행되는 어플리케이션은 제약이 있습니다. 각 가상머신은 자체 커널을 실행하기 때문에 이런 제약이 없습니다.

이는 커널에만 국한된게 아니르 특정 하드웨어 아키텍처용으로 만들어진 컨테이너화된 어플리케이션은 해당 아키텍처 시스템에서만 실행될 수 있다는 점을 알아야합니다.

x86 아키텍처용으로 만들어진 어플리케이션을 ARM 기반 컴퓨터에서 Docker 가 실행된다고해서 컨테이너화할 수 없습니다. 여전히 가상머신이 필요합니다.

### Introducing rkt—an alternative to Docker

Docker 넌 최초의 컨테이너 플랫폼입니다. 도커 자체가 프로세스 격리를 제공하지 않습니다. 컨테이너의 격리는 리눅스 네임스페이스와 `cgroup` 과 같은 커널 기능으로 리눅스 커널 수준에서 수행합니다. Docker 는 이런 기능을 사용하기 쉽게 합니다.

Docker 이후 컨테이너 형식과 런타임에 관한 개방된 업계 표준을 만들기 위해 **OCI(Open Container Initiative)** 가 탄생했습니다. Docker 도 또 다른 리눅스 컨테이너 엔진인 rkt 과 마찬가지로 이 이니셔티브의 일부입니다.

rkt 도 컨테이너 실행 플랫폼입니다. 보안, 결헙상, 공개, 표준 준수에 중점을 둡니다. OCI 컨테이너 이미지 형식을 사용하며 일반 Docker 컨테이너 이미지를 실행할 수 있습니다.

Docker 를 Kubernetes 의 컨테이너 런타임으로 사용하는 데 중점을 둡니다. 최근 Kubernetes 의 컨테이너 런타임으로 rkt 를 지원하기 시작했습니다.

## Introducing Kubernetes

시스템에 배포 가능한 어플리케이션 구성 요소의 수가 많아짐에 따라 모든 구성 요소의 관리가 어려워지는 것을 알았습니다. 엄청난 규모의 배포 관리를 효율적으로 처리할 수 있는 솔루션이 필요했습니다.

### Understanding its origins

구굴은 Borg 라는 내부 시스템을 개발해 어플리케이션 개발자와 시스템 관리자가 수천개의 어플리케이션과 서비스를 관리하는 데 도움을 줬습니다.

이 Borm, Omega, 내부 시스템으로 얻은 경험을 기반으로 오픈소스 시스템인 Kubernetes 를 출시했습니다.

### Looking at Kubernetes from the top of a mountain

Kubernetes 는 컨테이너화된 어플리케이션을 쉽게 배포하고 관리할 수 있게 해주는 시스템입니다. 리눅스 컨테이너의 기능에 의존해 어플리케이션의 내부 세부 사항을 알 필요 없이, 각 호스트에 어플리케이션을 수동으로 배포하지 않고도 이기종 어플리케이션을 실행할 수 있습니다.

어플리케이션은 컨테이너에서 실행되어 동일한 서버에서 실행되는 다른 어플리케이션에 영향을 미치지 않으며, 이는 완전히 다른 조직의 어플리케이션을 실행할 때 매우 중요합니다. 호스팅된 어플리케이션을 완전히 격리하면서 하드웨어를 최대한 활용하려고 노력하는 클라우드 제공업체에 매우 중요합니다.

Kubernetes 를 사용하면 모든 노드가 하나의 컴퓨터인 것처럼 수천 대의 컴퓨터 노드에서 소프트웨어 어플리케이션을 실행할 수 있습니다. 기본 인프라를 추상화하고 개발과 운영 팀 모두의 개발, 배포, 관리를 단순화합니다.

클러스터에 노드가 몇개가 있든 Kubernetes 에 어플리케이션을 배포하는 것은 항상 동일합니다. 클러스터의 크기와는 상관 없습니다. 클러스터 노드를 추가하는 것은 단순히 배포된 어플리케이션이 사용 가능한 리소스 양이 추가됩니다.

#### Understanding the core of what Kubernetes does

`Example 8` 은 Kubernetes 시스템의 가장 간단한 모습입니다. 시스템은 **마스터(Master)** 노드와 여러 **워커 노드(Worker Node)** 로 구성됩니다. 개발자가 어플리케이션 매니페스트를 마스터에게 게시하면 Kubernetes 는 해당 어플리케이션을 워커 노드 클러스터에 배포합니다. 구성 요소가 어떤 노드에 배포되든지 개발자나 시스템 관리자에게 중요하지 않습니다.

> Example 8 - Kubernetes exposes the whole datacenter as a single deployment platform

![image](https://user-images.githubusercontent.com/44635266/79061508-ea570c00-7ccb-11ea-8c09-095e1d925e94.png)

특정 어플리케이션이 함께 실행되도록 지정할 수 있으며 Kubernetes 는 여러 어플리케이션을 동일한 워커 노드에 배포합니다. 다른 어플리케이션은 클러스터에 걸쳐 분산되지만 배포된 위치에 상관없이 동일한 방식으로 서로 통신할 수 있습니다.

#### Helping developers focus on the core app features

Kubernetes 는 클러스터의 운영체제로 생각할 수 있습니다. 어플리케이션 개발자가 특정 인프라 관련 서비스를 어플리케이션에 구현하지 않아도 됩니다. Kubernetes 에 의존해 이런 서비스를 제공합니다. 여기는 서비스, 디스커버리, 스케일링, 자가 치유, 리더 선출 같은 것들이 포함됩니다.

따라서 어플리케이션 개발자는 인프라를 통합하는 방법에 시간을 낭비하지 않고 실제 기능을 구현하는 데 집중할 수 있습니다.

#### Helping ops teams achieve better resource utilization

Kubernetes 는 클러스터에 컨테이너화된 어플리케이션을 실행하고 구성 요소 간에 서로를 찾는 방법에 관한 정보를 제공하고 모든 어플리케이션을 계속 실행하게 합니다. 어플리케이션은 어떤 노드에서 실행되든 상관없기 때문에 Kubernetes 는 언제든지 어플리케이션을 재배치하고 어플리케이션을 조합하여 리소스를 수동 스케줄링보다 훨씬 더 잘 활용할 수 있습니다.

### Understanding the architecture of a Kubernetes cluster

Kubernetes 는 아키텍처를 개략적으로 살펴봤습니다. 이제 Kubernetes 클러스터가 어떻게 구성돼는지 살펴보겠습니다. 하드웨어 수준에서 Kubernetes 클러스터는 여러 노드로 구성되며, 두 가지 유형으로 나눌 수 있습니다.

* 마스터 노드는 전체 Kubernetes 시스템을 제어하고 관리하는 Kubernetes 컨트롤 플레인을 실행한다.
* 워커 노드는 실제 배포되는 컨테이너 어플리케이션을 실행한다.

`Example 9` 는 이 두 노드에서 실행되는 구성 요소를 보여줍니다.

> Example 9 - The components that make up a Kubernetes cluster

![image](https://user-images.githubusercontent.com/44635266/79061606-e4adf600-7ccc-11ea-9348-1af5f8ea4f92.png)

#### Control Plane

**컨트롤 플레인(Control Plane)** 은 클러스터를 제어하고 작동시킵니다. 하나의 마스터 노드에서 실행하거나 여러 노드로 분할되고 복제돼 고가용성을 보장할 수 있는 여러 구성 요소로 구성됩니다. 그 구성 요소는 다음과 같습니다.

* Kubernetes API 서버는 사용자, 컼ㄴ트롤 플레인 구성 요소와 통신한다.
* 스케줄러는 어플리케이션의 배포를 담당한다.
* 컨트롤러 매니저는 구성 요소 복제본, 워커 노드 추적, 노드 장애 처리 등과 같은 클러스터단의 기능을 수행한다
* Etcd 는 클러스터 구성을 지속적으로 저장하는 신뢰할 수 있는 분산 데이터 저장소다

컨트롤 플레인의 구성 요소는 클러스터 상태를 유지하고 제어하지만 어플리케이션을 실행하지 않습니다. 이는 노드에 의해 이루어집니다.

#### Node

워커 노드는 컨테이너화된 어플리케이션을 실행하는 시스템입니다. 어플리케이션을 실행하고 모니터링하며 어플리케이션에 서비스를 제공하는 작업은 다음 구성 요소에 의해 수행됩니다.

* 컨테이너를 실행하는 Docker, rkt 또는 다른 컨테이너 런타임
* API 서버와 통신하고 노드의 컨테이너를 관리하는 Kubelet
* 어플리케이션 구성 요소 간에 네트워크 트래픽을 로드밸런싱하는 **Kubernetes 서비스 프록시(kube-proxy)**

### Running an application in Kubernetes

Kubernetes 에 어플리케이션을 실행하려면 먼저 어플리케이션을 하나 이상의 컨테이너 이미지로 패키징하고 해당 이미지를 이미지 레지스트리로 푸시한 다음 Kubernetes API 서버에 어플리케이션 디스크립션을 게시해야 합니다.

이 디스크립션에는 컨테이너 이미지, 어플리케이션 구성 요소가 포함된 이미지, 해당 구성 요소가 서로 통신하는 방법, 동일 서버에 함께 배치돼야 하는 구성 요소와 같은 정보가 포함됩니다. 실행할 각 구성 요소의 복제본 수를 지정할 수 있습니다. 이 디스크립션에는 내부 또는 외부 클라이언트에 서비스를 제공하는 구성 요소와 하나의 IP 주소로 노출해 다른 구성 요소에서 검색 가능하게 해야 하는 구성 요소가 포함딥니다.

#### Understanding how the description results in a running container

API 서버가 어플리케이션 디스크립션을 처리할 때 스케줄러는 각 컨테이너가 필요한 리소스를 게산하고 해당 시점에 각 노드에 할당되지 않은 리소스를 기반으로 사용 가능한 워커 노드에 지정된 컨테이너를 할당합니다. 그 다음 Kuebelet 은 컨테이너 런타임에 필요한 컨테이너 이미지를 가져와 컨테이너를 실행하도록 지시합니다.

`Example 10` 을 보면 Kubernetes 에 어플리케이션을 어떻게 배포하는지 알 수 있습니다. 어플리케이션 디스크립터는 3 개 세트로 그룹화된 4 개의 컨테이너를 가집니다. 처음 두 파드는 하나의 컨테이너만 가지고 마지막 파드에는 2 개의 컨테이너가 있습니다. 즉 2 컨테이너를 함께 배치해야 하며 서로 격리해서는 안됩니다.

각 파드 옆에는 병렬로 실행해야 하는 각 파드의 복제본 수를 나타내는 숫자도 있습니다. 디스크립터를 Kubernetes 에 제출한 후 각 파드의 지정된 복제본 수를 사용 가능한 워커 노드로 할당합니다. 노드의 Kubelet 는 Docker 이미지 레지스트리에 컨테이너 이미지를 가져와 컨테이너를 실행하도록 지시합니다.

> Example 10 - A basic overview of the Kubernetes architecture and an application running on top of it

![image](https://user-images.githubusercontent.com/44635266/79061703-c1377b00-7ccd-11ea-9d2b-959663ba58b0.png)

#### Keeping the containers running

어플리케이션이 실행되면 Kubernetes 는 어플리케이션의 배포 상태가 사용자가 제공한 디스크립션과 일치하는지 지속적으로 확인합니다. 예를 들어 항상 5 개의 웹 서버 인스턴스를 실행하도록 지정하면 Kubernetes 는 항상 정확히 5 개의 인스턴스를 계속 실행합니다. 프로세스가 중단되거나 응답이 중지될 때와 같이 인스턴스가 제대로 작동하지 않으면 Kubernetes 가 자동으로 다시 시작합니다.

마찬가지로 워커 노드 전체가 종료되거나 액세스할 수 없게 되면 Kubernetes 는 이 노드에서 실행 중인 모든 컨테이너의 노드를 새로 스케줄링하고, 새로 선택한 노드에서 실행합니다.

#### Scaling the number of copies

Kubernetes 는 추가 복제본을 기동하고나 초과 복제본을 정지시킬 수 있습니다. 최적의 복제본 수를 결정하는 작업을 Kubernetes 에 맡길 수 있습니다. CPU 부하, 메모리 사용량, 어플리케이션이 노출하는 다른 메트릭과 같은 실시간 메트릭을 기반으로 복제본 수를 자동으로 조정할 수 있습니다.

#### Hitting a moving target

Kubernetes 는 컨테이너를 안에서 이동시킬 수 있습니다. 실행 중인 노드가 정지되거나 다른 컨테이너를 위한 공간을 만들려고 노드에서 제거할 때 발생합니다.

클라이언트가 특정 서비스를 제공하는 컨테이너를 쉽게 찾을 수 있도록 Kubernetes 에 동일한 서비스를 제공하는 컨테이너를 알려주면 Kubernetes 는 하나의 고정 IP 주소로 모든 컨테이너를 노출하고 해당 주소를 클러스터에서 실행중인 모든 어플리케이션에 노출합니다. 이는 환경변수로 제공되지만 클라이언트는 오래전부터 사용된 DNS 로 서비스 IP 를 조회할 수 있습니다.

kube-proxy` 는 제공하는 모든 컨테이너에서 서비스 연결이 로드밸런싱되도록합니다. 서비스의 IP 주소는 일정하게 유지 되므로 클라이언트는 컨테이너 클러스터 내에서 이동하더라도 컨테이너에 항상 연결할 수 있습니다.

### Understanding the benefits of using Kubernetes

모든 서버에 Kubernetes 를 설치한 경우 운영 팀이 더 이상 어플리케이션 배포를 처리할 필요가 없습니다. 컨테이너화된 어플리케이션은 이미 실행에 필요한 모든 것이 포함돼 있으므로 시스템 관리자는 어플리케이션을 배포하고 실행하기 위해 아무것도 설치할 필요가 없습니다.

Kubernetes 가 배포된 모든 노드에서는 시스템 관리자의 도움 없이 즉시 어플리케이션을 실행할 수 있습니다.

#### Simplifying application deployment

Kubernetes 는 모든 워커 노드를 하나의 배포 플랫폼으로 제공하기 때문에 어플리케이션 개발자는 자체적으로 어플리케이션 배포를 시작할 수 있으며 클러스터를 구성하는 서버에 관해 알 필요가 없습니다.

모든 노드는 어플리케이션이 해당 노드를 사용하기를 기다리는 하나의 컴퓨팅 리소스입니다. 서버는 어플리케이션에 적절한 시스템 리소스를 제공할 수 있는 한 어플리케이션이 어느 서버에 실행 중인지 신경 쓰지 않습니다.

개발자가 어플리케이션을 특정 종류의 하드웨어에서 실행해야 하는 경우가 있습니다. 노드가 이기종인 경우 특정 기능이 있는 노드에서 어플리케이션을 실행하고 다른 어플리케이션은 다른 노드에서 실행하는 경우가 있습니다. 예를 들어, 어플리케이션 중 하나가 HDD 대신 SDD 가 있는 시스템에 실행돼도 상관없을 경우 특정 어플리케이션이 SDD 가 있는 노드에 할당 되도록 해야합니다.

Kubernetes 를 사용하면 어플리케이션을 실행할 특정 노드를 선택하는 대신 Kubernetes 에 SSD 가 있는 노드 중 하나만 선택하도록 지시하면 됩니다.

#### Achieving better utilization of hardware

Kubernetes 를 설정하고 어플리케이션을 실행하여 인프라와 어플리케이션을 분리할 수 있습니다. Kubernetes 에 어플리케이션을 실행하도록 지시하면 어플리케이션의 리소스 요구 사항에 대한 디스크립션과 각 노드에서 사용 가능한 리소스에 따라 어플리케이션을 실행할 가장 적합한 노드를 선택할 수 있습니다.

컨테이너를 사용하고 어플리케이션을 클러스터의 특정 노드로 지정하지 않으면 언제든지 어플리케이션이 클러스터 간에 자유롭게 이동할 수 있으므로 클러스터에서 실행되는 다른 어플리케이션 구성 요소를 혼합해 클러스터 노드에 배치할 수 있습니다. 노드의 하드웨어 리소스를 최대한 활용할 수 있습니다.

Kubernetes 는 언제든지 클러스터 간에 어플리케이션이 이동할 수 있으므로 수동으로 수행하는 것보다 훨씬 더 인프라를 잘 활용할 수 있습니다. 

#### Health checking and self-healing

서버 장애시 클러스터 간에 어플리케이션을 이동할 수 있는 시스템을 갖추는 것도 중요합니다.

Kubernetes 는 노드 장애 발생 시 자동으로 다른 노드로 스케줄링합니다. 이로써 운영 팀은 어플리케이션 구성 요소를 수동으로 마이그레이션할 필요가 없이, 노드 자체를 수정해 사용 가능한 하드웨어 리소스 풀에 반환하는 데 집중할 수 있습니다.

인프라에 장애가 발생한 노드가 없어도 정상적인 시스템 작동이 가능하도록 충분한 예비 자원이 있는 경우 운영 팀은 새벽 3 시에 일어난 장애에 즉시 대응할 필요가 없습니다.

#### Automatic scaling

Kubernetes 를 사용하여 배포된 어플리케이션을 관리할 때 리소스릉 모니터링하고 각 어플리케이션의 실행 중인 인스턴스 수를 계속 조정하도록 지시할 수 있습니다.

클라우드 인프라에서 Kubernetes 가 실행 중인 경우 클라우드 제공업체의 API 로 쉽게 노드를 추가하면 배포된 어플리케이션의 부하에 따라 전체 클러스터 크기를 자동으로 확장하거나 축소할 수 있습니다.

#### Simplifying application development

개발자가 일반적으로 구현해야 하는 기능을 구현할 필요가 없어집니다. 여기에는 클러스터된 어플리케이션에서 서비스나 피어를 검색하는 기능도 포함됩니다. Kubernetes 가 이 작업을 대신 수행합니다. 일반적으로 어플리케이션은 특정 환경 변수만 조회하거나 DNS 조회만 수행하면 됩니다. 충분하지 않다면, 어플리케이션에서 Kubernetes 서버를 직접 쿼리해 해당 정보나 다른 정보를 얻을 수 있습니다. Kubernetes API 서버를 쿼리하면 개발자가 리더 선정 같은 복잡한 메커니즘을 구현하지 않아도 됩니다.

